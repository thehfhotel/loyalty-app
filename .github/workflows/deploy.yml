name: Optimized CI/CD Pipeline with Security & Testing

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main]
  workflow_dispatch:

# Workflow-level concurrency: prevent parallel runs on same branch
# This prevents race conditions when multiple commits push in quick succession
# Dependabot PRs share a single concurrency group to prevent parallel runs
# Main and develop branches don't cancel in-progress runs (queue instead)
concurrency:
  group: ${{ github.actor == 'dependabot[bot]' && 'dependabot-ci' || format('ci-{0}', github.ref) }}
  cancel-in-progress: ${{ github.ref != 'refs/heads/main' && github.ref != 'refs/heads/develop' && github.actor != 'dependabot[bot]' }}

# SECURITY: Top-level permissions set to minimal read-only
# Write permissions are granted at job-level only where needed (principle of least privilege)
permissions:
  contents: read
  actions: read
  pull-requests: read

env:
  NODE_VERSION: 24
  CACHE_VERSION: v3

jobs:
  # =============================================================================
  # PHASE 0: SHARED WORKSPACE PREPARATION (NEW - 30-60 seconds)
  # =============================================================================

  prepare-workspace:
    name: "üöÄ Workspace Preparation"
    runs-on: self-hosted
    timeout-minutes: 2
    outputs:
      workspace-ready: ${{ steps.setup-complete.outputs.ready }}
      backend-cache-hit: ${{ steps.backend-cache.outputs.cache-hit }}
      frontend-cache-hit: ${{ steps.frontend-cache.outputs.cache-hit }}

    steps:
      - name: "üì• Checkout code (shared for all jobs)"
        uses: actions/checkout@8e8c483db84b4bee98b60c0593521ed34d9990e8 # v6
        with:
          fetch-depth: 1
          clean: true

      - name: "‚ö° Setup Node.js"
        uses: actions/setup-node@395ad3262231945c25e8478fd5baf05154b1d79f # v6
        with:
          node-version: ${{ env.NODE_VERSION }}

      - name: "üóÇÔ∏è Prepare directories"
        run: |
          # Verify Node.js version
          echo "üîç Node.js: $(node --version) | npm: $(npm --version)"
          NODE_MAJOR=$(node --version | cut -d'.' -f1 | tr -d 'v')
          if [ "$NODE_MAJOR" -lt "${{ env.NODE_VERSION }}" ]; then
            echo "‚ùå Node.js version mismatch! Expected ${{ env.NODE_VERSION }}.x, got $(node --version)"
            exit 1
          fi

          echo "üóëÔ∏è Removing old cache versions..."
          find /tmp/runner-cache -maxdepth 1 -type d ! -name "${{ env.CACHE_VERSION }}" ! -name "runner-cache" ! -name "workspace" -exec rm -rf {} + 2>/dev/null || true

          echo "üßπ Clearing stale Playwright and Allure artifacts..."
          rm -rf allure-results test-results backend/allure-results frontend/allure-results 2>/dev/null || true
          mkdir -p allure-results test-results backend/allure-results frontend/allure-results

          echo "üì¶ Setting up versioned cache directories..."
          mkdir -p /tmp/runner-cache/${{ env.CACHE_VERSION }}/{npm,backend-node_modules,frontend-node_modules,root-node_modules}

          echo "‚úÖ Directories prepared (cache version: ${{ env.CACHE_VERSION }})"

      - name: "üì¶ Restore/install backend dependencies"
        id: backend-cache
        working-directory: ./backend
        run: |
          CACHE_DIR="/tmp/runner-cache/${{ env.CACHE_VERSION }}/backend-node_modules"
          LOCK_HASH=$(sha256sum package-lock.json | cut -d' ' -f1)

          # Check cache validity
          if [ -f "$CACHE_DIR/.lock-hash" ] && [ -d "$CACHE_DIR/node_modules" ]; then
            CACHED_HASH=$(cat "$CACHE_DIR/.lock-hash")
            if [ "$LOCK_HASH" = "$CACHED_HASH" ]; then
              echo "‚úÖ Cache hit - restoring backend node_modules (hash: ${LOCK_HASH:0:12}...)"
              cp -r "$CACHE_DIR/node_modules" ./
              echo "cache-hit=true" >> $GITHUB_OUTPUT
              exit 0
            fi
            echo "‚ö†Ô∏è Cache invalidated: ${CACHED_HASH:0:12}... ‚Üí ${LOCK_HASH:0:12}..."
            rm -rf "$CACHE_DIR"
            mkdir -p "$CACHE_DIR"
          else
            echo "‚ùå No valid cache found"
          fi

          # Install and save to cache
          echo "üì¶ Installing backend dependencies..."
          npm ci --cache /tmp/runner-cache/${{ env.CACHE_VERSION }}/npm --prefer-offline --include=dev

          echo "üíæ Saving to cache..."
          flock -w 60 "$CACHE_DIR/.flock" bash -c "
            rm -rf '$CACHE_DIR/node_modules'
            cp -r node_modules '$CACHE_DIR/'
            echo '$LOCK_HASH' > '$CACHE_DIR/.lock-hash'
          "
          echo "cache-hit=false" >> $GITHUB_OUTPUT
          echo "‚úÖ Backend dependencies installed and cached"

      - name: "üì¶ Restore/install frontend dependencies"
        id: frontend-cache
        working-directory: ./frontend
        run: |
          CACHE_DIR="/tmp/runner-cache/${{ env.CACHE_VERSION }}/frontend-node_modules"
          LOCK_HASH=$(sha256sum package-lock.json | cut -d' ' -f1)

          # Check cache validity
          if [ -f "$CACHE_DIR/.lock-hash" ] && [ -d "$CACHE_DIR/node_modules" ]; then
            CACHED_HASH=$(cat "$CACHE_DIR/.lock-hash")
            if [ "$LOCK_HASH" = "$CACHED_HASH" ]; then
              echo "‚úÖ Cache hit - restoring frontend node_modules (hash: ${LOCK_HASH:0:12}...)"
              cp -r "$CACHE_DIR/node_modules" ./
              echo "cache-hit=true" >> $GITHUB_OUTPUT
              exit 0
            fi
            echo "‚ö†Ô∏è Cache invalidated: ${CACHED_HASH:0:12}... ‚Üí ${LOCK_HASH:0:12}..."
            rm -rf "$CACHE_DIR"
            mkdir -p "$CACHE_DIR"
          else
            echo "‚ùå No valid cache found"
          fi

          # Install and save to cache
          echo "üì¶ Installing frontend dependencies..."
          npm ci --cache /tmp/runner-cache/${{ env.CACHE_VERSION }}/npm --prefer-offline

          echo "üíæ Saving to cache..."
          flock -w 60 "$CACHE_DIR/.flock" bash -c "
            rm -rf '$CACHE_DIR/node_modules'
            cp -r node_modules '$CACHE_DIR/'
            echo '$LOCK_HASH' > '$CACHE_DIR/.lock-hash'
          "
          echo "cache-hit=false" >> $GITHUB_OUTPUT
          echo "‚úÖ Frontend dependencies installed and cached"

      - name: "üì¶ Restore/install root dependencies"
        run: |
          CACHE_DIR="/tmp/runner-cache/${{ env.CACHE_VERSION }}/root-node_modules"
          LOCK_HASH=$(sha256sum package-lock.json | cut -d' ' -f1)

          # Check cache validity
          if [ -f "$CACHE_DIR/.lock-hash" ] && [ -d "$CACHE_DIR/node_modules" ]; then
            CACHED_HASH=$(cat "$CACHE_DIR/.lock-hash")
            if [ "$LOCK_HASH" = "$CACHED_HASH" ]; then
              echo "‚úÖ Cache hit - restoring root node_modules (hash: ${LOCK_HASH:0:12}...)"
              cp -r "$CACHE_DIR/node_modules" ./
              exit 0
            fi
            echo "‚ö†Ô∏è Cache invalidated: ${CACHED_HASH:0:12}... ‚Üí ${LOCK_HASH:0:12}..."
            rm -rf "$CACHE_DIR"
            mkdir -p "$CACHE_DIR"
          else
            echo "‚ùå No valid cache found"
          fi

          # Install and save to cache
          echo "üì¶ Installing root dependencies (Playwright)..."
          npm ci --cache /tmp/runner-cache/${{ env.CACHE_VERSION }}/npm --prefer-offline

          echo "üíæ Saving to cache..."
          flock -w 60 "$CACHE_DIR/.flock" bash -c "
            rm -rf '$CACHE_DIR/node_modules'
            cp -r node_modules '$CACHE_DIR/'
            echo '$LOCK_HASH' > '$CACHE_DIR/.lock-hash'
          "
          echo "‚úÖ Root dependencies installed and cached"

      - name: "üîß Generate Prisma client & share workspace"
        id: setup-complete
        run: |
          echo "üîß Generating Prisma client..."
          cd backend && npm run db:generate

          if [ ! -d "src/generated/prisma" ]; then
            echo "‚ùå Prisma client generation failed"
            exit 1
          fi
          cd ..

          echo "üì§ Copying workspace to shared location..."
          SHARED_WORKSPACE="/tmp/runner-cache/workspace/${{ github.run_id }}"
          mkdir -p "$SHARED_WORKSPACE"

          rsync -a --exclude='.git' \
                   --exclude='node_modules' \
                   --exclude='backend/node_modules' \
                   --exclude='frontend/node_modules' \
                   --exclude='*.backup' \
                   . "$SHARED_WORKSPACE/"

          echo "‚úÖ Workspace preparation complete"
          echo "   Backend cache: ${{ steps.backend-cache.outputs.cache-hit && 'hit' || 'miss' }}"
          echo "   Frontend cache: ${{ steps.frontend-cache.outputs.cache-hit && 'hit' || 'miss' }}"
          echo "ready=true" >> $GITHUB_OUTPUT

  # =============================================================================
  # PHASE 1: VALIDATION & TESTING (Security, Unit Tests, Integration Tests)
  # =============================================================================

  validate-and-test:
    name: "üîíüß™ Security, Unit & Integration Tests"
    runs-on: self-hosted
    needs: prepare-workspace
    timeout-minutes: 12
    permissions:
      pull-requests: write
      contents: read
    concurrency:
      group: validate-and-test
      cancel-in-progress: false
    outputs:
      security-passed: ${{ steps.security-results.outputs.passed }}
      unit-tests-passed: ${{ steps.unit-test-results.outputs.passed }}
      integration-tests-passed: ${{ steps.integration-test-results.outputs.passed }}
      coverage-percent: ${{ steps.unit-test-results.outputs.coverage }}

    steps:
      # =========================================================================
      # SETUP (shared across all phases)
      # =========================================================================
      - name: "üì• Copy shared workspace & restore backend/frontend dependencies"
        run: |
          SHARED_WORKSPACE="/tmp/runner-cache/workspace/${{ github.run_id }}"
          if [ ! -d "$SHARED_WORKSPACE" ]; then
            echo "‚ùå Shared workspace not found at $SHARED_WORKSPACE"
            exit 1
          fi
          rsync -a --delete "$SHARED_WORKSPACE/" .
          echo "‚úÖ Workspace ready (stale files removed)"

          echo "üì¶ Restoring backend node_modules..."
          cp -r /tmp/runner-cache/${{ env.CACHE_VERSION }}/backend-node_modules/node_modules ./backend/ || exit 1

          echo "üì¶ Restoring frontend node_modules..."
          cp -r /tmp/runner-cache/${{ env.CACHE_VERSION }}/frontend-node_modules/node_modules ./frontend/ || exit 1

          echo "‚úÖ Dependencies restored"

      - name: "‚ö° Setup Node.js runtime environment"
        uses: actions/setup-node@395ad3262231945c25e8478fd5baf05154b1d79f # v6
        with:
          node-version: ${{ env.NODE_VERSION }}

      # =========================================================================
      # PHASE 1: SECURITY & CODE QUALITY
      # =========================================================================
      - name: "üîí Security & code quality: TypeScript, ESLint, npm audit, validations"
        id: security-results
        run: |
          # Timing helper - shows duration after each step
          STEP_START=$(date +%s)
          show_time() {
            local name="$1"
            local start="$2"
            local duration=$(($(date +%s) - start))
            echo "  ‚è±Ô∏è  $name completed in ${duration}s"
          }

          # Verify Node.js version
          echo "üîç Node.js: $(node --version) | npm: $(npm --version)"
          NODE_MAJOR=$(node --version | cut -d'.' -f1 | tr -d 'v')
          if [ "$NODE_MAJOR" -lt "${{ env.NODE_VERSION }}" ]; then
            echo "‚ùå Node.js version mismatch! Expected: ${{ env.NODE_VERSION }}.x, Got: $(node --version)"
            exit 1
          fi

          echo ""
          echo "=========================================="
          echo "üîç TypeScript type checking"
          echo "=========================================="
          T1=$(date +%s)
          echo "Checking backend..."
          cd backend
          set +e
          npm run typecheck 2>&1 | grep -E "error|warning|Error|Warning" || true
          TSC_BACKEND=${PIPESTATUS[0]}
          set -e
          if [ $TSC_BACKEND -ne 0 ]; then
            echo "‚ùå Backend TypeScript check failed"
            exit 1
          fi

          echo "Checking frontend..."
          cd ../frontend
          set +e
          npm run typecheck 2>&1 | grep -E "error|warning|Error|Warning" || true
          TSC_FRONTEND=${PIPESTATUS[0]}
          set -e
          if [ $TSC_FRONTEND -ne 0 ]; then
            echo "‚ùå Frontend TypeScript check failed"
            exit 1
          fi
          cd ..
          echo "‚úÖ TypeScript checks passed"
          show_time "TypeScript" $T1

          echo ""
          echo "=========================================="
          echo "üåê Translation key validation"
          echo "=========================================="
          T_TRANS=$(date +%s)
          cd frontend
          set +e
          npm run check:translations 2>&1
          TRANS_EXIT=$?
          set -e
          if [ $TRANS_EXIT -ne 0 ]; then
            echo "‚ùå Missing translation keys found"
            exit 1
          fi
          echo "‚úÖ All translation keys present"
          cd ..
          show_time "Translations" $T_TRANS

          echo ""
          echo "=========================================="
          echo "üîí Security linting (ESLint + security rules)"
          echo "=========================================="
          T2=$(date +%s)
          cd backend
          set +e
          npm run lint:security 2>&1 | tee /tmp/lint-output.log | grep -E "warning|error|Warning|Error" || true
          LINT_EXIT=${PIPESTATUS[0]}
          set -e
          ERROR_COUNT=$(grep -oP '‚úñ.*\(\K[0-9]+(?= error)' /tmp/lint-output.log 2>/dev/null || echo "0")
          if [ "$ERROR_COUNT" != "0" ]; then
            echo "‚ùå ESLint found $ERROR_COUNT errors"
            exit 1
          fi
          echo "‚úÖ Security linting passed"
          cd ..
          show_time "ESLint" $T2

          echo ""
          echo "=========================================="
          echo "üõ°Ô∏è npm security audit"
          echo "=========================================="
          T3=$(date +%s)
          cd backend
          set +e
          npm audit --audit-level=moderate 2>&1 | grep -E "vulnerabilities|critical|high|moderate|Severity" || echo "No vulnerabilities found"
          AUDIT_EXIT=${PIPESTATUS[0]}
          set -e
          if [ $AUDIT_EXIT -ne 0 ]; then
            echo "‚ùå npm audit found security vulnerabilities"
            exit 1
          fi
          echo "‚úÖ npm audit passed"
          show_time "npm audit" $T3

          echo ""
          echo "=========================================="
          echo "üîí Custom security validation"
          echo "=========================================="
          T4=$(date +%s)
          node scripts/validate-security.js || exit 1
          cd ..
          show_time "Security validation" $T4

          echo ""
          echo "=========================================="
          echo "üõ°Ô∏è Test integrity validation"
          echo "=========================================="
          T5=$(date +%s)
          if [ -f "./scripts/validate-test-integrity.sh" ]; then
            ./scripts/validate-test-integrity.sh || exit 1
          else
            echo "‚ö†Ô∏è Test integrity script not found - skipping"
          fi
          show_time "Test integrity" $T5

          echo ""
          echo "=========================================="
          echo "üîê Environment & secrets validation"
          echo "=========================================="
          T6=$(date +%s)
          if [ -f "./scripts/validate-environment.sh" ]; then
            ./scripts/validate-environment.sh build || exit 1
          fi
          echo "‚úÖ Environment validation passed"
          show_time "Environment" $T6

          echo ""
          echo "=========================================="
          echo "üîê Enhanced security audit (20-user prototype)"
          echo "=========================================="
          T7=$(date +%s)
          ./scripts/security-audit.sh || exit 1
          show_time "Security audit" $T7

          # Summary
          TOTAL=$(($(date +%s) - STEP_START))
          echo ""
          echo "=========================================="
          echo "‚úÖ All security & code quality checks passed"
          echo "   Total time: ${TOTAL}s"
          echo "=========================================="
          echo "passed=true" >> $GITHUB_OUTPUT

      # =========================================================================
      # PHASE 2: START SHARED TEST CONTAINERS
      # =========================================================================
      - name: "üê≥ Start shared postgres/redis containers & create unit + integration databases"
        run: |
          cat > docker-compose.test.yml << 'EOF'
          services:
            postgres:
              image: postgres:15-alpine
              container_name: loyalty_postgres_test
              environment:
                POSTGRES_USER: loyalty
                POSTGRES_PASSWORD: loyalty_password
                POSTGRES_DB: loyalty_db
              ports:
                - "5438:5432"
              volumes:
                - loyalty_postgres_test_data:/var/lib/postgresql/data
              healthcheck:
                test: ["CMD-SHELL", "pg_isready -U loyalty -d loyalty_db"]
                interval: 5s
                timeout: 5s
                retries: 5

            redis:
              image: redis:7-alpine
              container_name: loyalty_redis_test
              ports:
                - "6383:6379"
              healthcheck:
                test: ["CMD", "redis-cli", "ping"]
                interval: 5s
                timeout: 3s
                retries: 5

          volumes:
            loyalty_postgres_test_data:
          EOF

          # Cleanup and start
          docker compose -f docker-compose.test.yml down -v 2>/dev/null || true
          docker compose -f docker-compose.test.yml up -d

          # Wait for services
          echo "‚è≥ Waiting for postgres..."
          timeout 60 bash -c 'until docker exec loyalty_postgres_test pg_isready -U loyalty; do sleep 2; done'
          echo "‚è≥ Waiting for redis..."
          timeout 30 bash -c 'until docker exec loyalty_redis_test redis-cli ping | grep -q PONG; do sleep 2; done'

          # Create both test databases
          echo "üóÑÔ∏è Creating test databases..."
          docker exec loyalty_postgres_test psql -U loyalty -d postgres -c "CREATE USER loyalty_unit WITH PASSWORD 'unit_password';" || true
          docker exec loyalty_postgres_test psql -U loyalty -d postgres -c "CREATE DATABASE loyalty_unit_db OWNER loyalty_unit;" || true
          docker exec loyalty_postgres_test psql -U loyalty -d postgres -c "GRANT ALL PRIVILEGES ON DATABASE loyalty_unit_db TO loyalty_unit;" || true
          docker exec loyalty_postgres_test psql -U loyalty_unit -d loyalty_unit_db -c "CREATE EXTENSION IF NOT EXISTS \"uuid-ossp\";" || true

          docker exec loyalty_postgres_test psql -U loyalty -d postgres -c "CREATE USER loyalty_integration WITH PASSWORD 'integration_password';" || true
          docker exec loyalty_postgres_test psql -U loyalty -d postgres -c "CREATE DATABASE loyalty_integration_db OWNER loyalty_integration;" || true
          docker exec loyalty_postgres_test psql -U loyalty -d postgres -c "GRANT ALL PRIVILEGES ON DATABASE loyalty_integration_db TO loyalty_integration;" || true
          docker exec loyalty_postgres_test psql -U loyalty_integration -d loyalty_integration_db -c "CREATE EXTENSION IF NOT EXISTS \"uuid-ossp\";" || true

          echo "‚úÖ Test containers ready (postgres:5438, redis:6383)"
          echo "   - loyalty_unit_db for unit tests"
          echo "   - loyalty_integration_db for integration tests"

      # =========================================================================
      # PHASE 3: UNIT TESTS
      # =========================================================================
      - name: "üß™ Unit tests: setup database, run Prisma migrations, execute tests with coverage"
        id: run-unit-tests
        working-directory: ./backend
        env:
          DATABASE_URL: postgresql://loyalty_unit:unit_password@localhost:5438/loyalty_unit_db
          REDIS_URL: redis://localhost:6383
          NODE_ENV: test
          JWT_SECRET: test-jwt-secret-for-testing-only-must-be-64-chars-minimum-xxxxxx
          JWT_REFRESH_SECRET: test-refresh-secret-for-testing-only-must-be-64-chars-minimum-xx
          SESSION_SECRET: test-session-secret-for-testing-only-min-32-chars
        run: |
          echo "üîß Setting up unit test database..."
          npm run db:generate
          npm run db:migrate:deploy
          echo "‚úÖ Unit test database ready"

          echo ""
          echo "üß™ Running unit tests with coverage..."
          npm run test:unit -- --coverage --passWithNoTests

      - name: "üìä Upload unit test coverage report (retained 30 days)"
        if: always()
        uses: actions/upload-artifact@330a01c490aca151604b8cf639adc76d48f6c5d4 # v5
        with:
          name: coverage-report-${{ github.run_id }}
          path: backend/coverage/
          retention-days: 30
          if-no-files-found: warn

      - name: "üìä Upload unit test Allure results (retained 7 days)"
        if: always()
        uses: actions/upload-artifact@330a01c490aca151604b8cf639adc76d48f6c5d4 # v5
        with:
          name: allure-results-unit-${{ github.run_id }}
          path: backend/allure-results/
          retention-days: 7
          if-no-files-found: warn

      - name: "üìà Evaluate unit test results & extract coverage metrics"
        id: unit-test-results
        if: always()
        run: |
          if [ "${{ steps.run-unit-tests.outcome }}" == "success" ]; then
            echo "‚úÖ Unit tests passed"
            echo "passed=true" >> $GITHUB_OUTPUT
          else
            echo "‚ùå Unit tests failed"
            echo "passed=false" >> $GITHUB_OUTPUT
          fi

          if [ -f backend/coverage/coverage-summary.json ]; then
            COVERAGE=$(jq '.total.lines.pct' backend/coverage/coverage-summary.json)
            echo "coverage=$COVERAGE" >> $GITHUB_OUTPUT
            echo "üìä Coverage: $COVERAGE%"
          else
            echo "coverage=0" >> $GITHUB_OUTPUT
          fi

      # =========================================================================
      # PHASE 4: INTEGRATION TESTS
      # =========================================================================
      - name: "üîó Integration tests: setup database, run Prisma migrations, execute API tests"
        id: run-integration-tests
        working-directory: ./backend
        env:
          DATABASE_URL: postgresql://loyalty_integration:integration_password@localhost:5438/loyalty_integration_db
          REDIS_URL: redis://localhost:6383
          NODE_ENV: test
          JWT_SECRET: test-jwt-secret-for-testing-only-must-be-64-chars-minimum-xxxxxx
          JWT_REFRESH_SECRET: test-refresh-secret-for-testing-only-must-be-64-chars-minimum-xx
          SESSION_SECRET: test-session-secret-for-testing-only-min-32-chars
        run: |
          echo "üîß Setting up integration test database..."
          npm run db:migrate:deploy
          echo "‚úÖ Integration test database ready"

          echo ""
          echo "üîó Running integration tests..."
          npm run test:integration

      - name: "üìä Upload integration test Allure results (retained 7 days)"
        if: always()
        uses: actions/upload-artifact@330a01c490aca151604b8cf639adc76d48f6c5d4 # v5
        with:
          name: allure-results-integration-${{ github.run_id }}
          path: backend/allure-results/
          retention-days: 7
          if-no-files-found: warn

      - name: "üóÑÔ∏è Database schema tests & migration validation"
        id: run-db-tests
        working-directory: ./backend
        env:
          DATABASE_URL: postgresql://loyalty_integration:integration_password@localhost:5438/loyalty_integration_db
          NODE_ENV: test
        run: |
          echo "üß™ Running database schema tests..."
          npm run test:db -- --passWithNoTests

          echo ""
          echo "üîç Running SQL query validation (validates all raw SQL against real database)..."
          npm run test:sql
          echo "‚úÖ SQL validation passed - all queries are syntactically correct"

          echo ""
          echo "üóÑÔ∏è Running database migration validation..."
          cd ..
          if [ -f "./scripts/validate-db-migration.sh" ]; then
            ./scripts/validate-db-migration.sh || echo "‚ö†Ô∏è DB migration validation failed (non-blocking)"
          fi
          echo "‚úÖ Database validation complete"

      - name: "üìà Evaluate integration test results (API tests + DB schema tests)"
        id: integration-test-results
        if: always()
        run: |
          INTEGRATION="${{ steps.run-integration-tests.outcome }}"
          DB_TESTS="${{ steps.run-db-tests.outcome }}"

          if [ "$INTEGRATION" == "success" ] && [ "$DB_TESTS" == "success" ]; then
            echo "‚úÖ All integration tests passed"
            echo "passed=true" >> $GITHUB_OUTPUT
          else
            echo "‚ùå Integration tests failed (integration: $INTEGRATION, db: $DB_TESTS)"
            echo "passed=false" >> $GITHUB_OUTPUT
            exit 1
          fi

      - name: "üìä Write test summary to job summary"
        if: always()
        run: |
          UNIT_PASSED="${{ steps.unit-test-results.outputs.passed }}"
          INTEGRATION_PASSED="${{ steps.integration-test-results.outputs.passed }}"

          # Determine status emoji
          if [ "$UNIT_PASSED" == "true" ]; then
            UNIT_STATUS="‚úÖ Passed"
          else
            UNIT_STATUS="‚ùå Failed"
          fi

          if [ "$INTEGRATION_PASSED" == "true" ]; then
            INTEGRATION_STATUS="‚úÖ Passed"
          else
            INTEGRATION_STATUS="‚ùå Failed"
          fi

          # Start summary
          echo "## üß™ Unit & Integration Test Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Test Suite | Status |" >> $GITHUB_STEP_SUMMARY
          echo "|:-----------|:-------|" >> $GITHUB_STEP_SUMMARY
          echo "| Unit Tests | $UNIT_STATUS |" >> $GITHUB_STEP_SUMMARY
          echo "| Integration Tests | $INTEGRATION_STATUS |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          # Coverage report
          if [ -f backend/coverage/coverage-summary.json ]; then
            echo "## üìä Test Coverage Report" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY

            LINES_COVERED=$(jq '.total.lines.covered' backend/coverage/coverage-summary.json)
            LINES_TOTAL=$(jq '.total.lines.total' backend/coverage/coverage-summary.json)
            LINES_PCT=$(jq '.total.lines.pct' backend/coverage/coverage-summary.json)

            STMTS_COVERED=$(jq '.total.statements.covered' backend/coverage/coverage-summary.json)
            STMTS_TOTAL=$(jq '.total.statements.total' backend/coverage/coverage-summary.json)
            STMTS_PCT=$(jq '.total.statements.pct' backend/coverage/coverage-summary.json)

            FUNCS_COVERED=$(jq '.total.functions.covered' backend/coverage/coverage-summary.json)
            FUNCS_TOTAL=$(jq '.total.functions.total' backend/coverage/coverage-summary.json)
            FUNCS_PCT=$(jq '.total.functions.pct' backend/coverage/coverage-summary.json)

            BRANCHES_COVERED=$(jq '.total.branches.covered' backend/coverage/coverage-summary.json)
            BRANCHES_TOTAL=$(jq '.total.branches.total' backend/coverage/coverage-summary.json)
            BRANCHES_PCT=$(jq '.total.branches.pct' backend/coverage/coverage-summary.json)

            echo "| Metric | Covered | Total | Percentage |" >> $GITHUB_STEP_SUMMARY
            echo "|:-------|--------:|------:|-----------:|" >> $GITHUB_STEP_SUMMARY
            echo "| Lines | $LINES_COVERED | $LINES_TOTAL | ${LINES_PCT}% |" >> $GITHUB_STEP_SUMMARY
            echo "| Statements | $STMTS_COVERED | $STMTS_TOTAL | ${STMTS_PCT}% |" >> $GITHUB_STEP_SUMMARY
            echo "| Functions | $FUNCS_COVERED | $FUNCS_TOTAL | ${FUNCS_PCT}% |" >> $GITHUB_STEP_SUMMARY
            echo "| Branches | $BRANCHES_COVERED | $BRANCHES_TOTAL | ${BRANCHES_PCT}% |" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
          fi

          # Test Coverage Statistics (Load Test, E2E, Integration)
          echo "## üìà Test Coverage Statistics" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          # Load Test Coverage
          if [ -f "backend/src/__tests__/performance/k6/coverage-manifest.json" ]; then
            LOAD_TESTED=$(jq '.testedEndpoints' backend/src/__tests__/performance/k6/coverage-manifest.json)
            LOAD_TOTAL=$(jq '.totalEndpoints' backend/src/__tests__/performance/k6/coverage-manifest.json)
            LOAD_PCT=$(awk "BEGIN {printf \"%.1f\", $LOAD_TESTED * 100 / $LOAD_TOTAL}")
            echo "### üîÑ Load Test Coverage" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "| Metric | Value |" >> $GITHUB_STEP_SUMMARY
            echo "|:-------|------:|" >> $GITHUB_STEP_SUMMARY
            echo "| Endpoints Tested | $LOAD_TESTED / $LOAD_TOTAL |" >> $GITHUB_STEP_SUMMARY
            echo "| Coverage | ${LOAD_PCT}% |" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
          fi

          # E2E Coverage
          if [ -f "tests/coverage-manifest.json" ]; then
            E2E_TESTED=$(jq '.testedPages' tests/coverage-manifest.json)
            E2E_TOTAL=$(jq '.totalPages' tests/coverage-manifest.json)
            E2E_PCT=$(awk "BEGIN {printf \"%.1f\", $E2E_TESTED * 100 / $E2E_TOTAL}")
            E2E_FLOWS=$(jq '.flows.tested' tests/coverage-manifest.json)
            E2E_FLOWS_TOTAL=$(jq '.flows.total' tests/coverage-manifest.json)
            echo "### üé≠ E2E Test Coverage" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "| Metric | Value |" >> $GITHUB_STEP_SUMMARY
            echo "|:-------|------:|" >> $GITHUB_STEP_SUMMARY
            echo "| Pages Tested | $E2E_TESTED / $E2E_TOTAL |" >> $GITHUB_STEP_SUMMARY
            echo "| Page Coverage | ${E2E_PCT}% |" >> $GITHUB_STEP_SUMMARY
            echo "| User Flows | $E2E_FLOWS / $E2E_FLOWS_TOTAL |" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
          fi

          # Integration Test Coverage Summary
          if [ -f backend/coverage/coverage-summary.json ]; then
            INT_LINES=$(jq '.total.lines.pct' backend/coverage/coverage-summary.json)
            INT_FUNCS=$(jq '.total.functions.pct' backend/coverage/coverage-summary.json)
            INT_BRANCH=$(jq '.total.branches.pct' backend/coverage/coverage-summary.json)
            echo "### üî¨ Code Coverage Summary" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "| Metric | Coverage |" >> $GITHUB_STEP_SUMMARY
            echo "|:-------|----------:|" >> $GITHUB_STEP_SUMMARY
            echo "| Lines | ${INT_LINES}% |" >> $GITHUB_STEP_SUMMARY
            echo "| Functions | ${INT_FUNCS}% |" >> $GITHUB_STEP_SUMMARY
            echo "| Branches | ${INT_BRANCH}% |" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
          fi

          # Download reports info
          echo "## üì• Download Reports" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "Coverage reports are available as workflow artifacts for 30 days." >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Report | Path |" >> $GITHUB_STEP_SUMMARY
          echo "|:-------|:-----|" >> $GITHUB_STEP_SUMMARY
          echo "| HTML Report | \`backend/coverage/lcov-report/index.html\` |" >> $GITHUB_STEP_SUMMARY
          echo "| LCOV Data | \`backend/coverage/lcov.info\` |" >> $GITHUB_STEP_SUMMARY
          echo "| JSON Summary | \`backend/coverage/coverage-summary.json\` |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

      # =========================================================================
      # FINAL: PR COMMENT & CLEANUP
      # =========================================================================
      - name: "üí¨ Post test results summary to pull request (unit + integration status)"
        if: always() && github.event_name == 'pull_request'
        uses: actions/github-script@ed597411d8f924073f98dfc5c65a23a2325f34cd # v8
        continue-on-error: true
        with:
          script: |
            const fs = require('fs');
            const unitPassed = '${{ steps.unit-test-results.outputs.passed }}' === 'true';
            const integrationPassed = '${{ steps.integration-test-results.outputs.passed }}' === 'true';

            const unitEmoji = unitPassed ? '‚úÖ' : '‚ùå';
            const integrationEmoji = integrationPassed ? '‚úÖ' : '‚ùå';

            let coverageSection = '';
            const coveragePath = 'backend/coverage/coverage-summary.json';
            if (fs.existsSync(coveragePath)) {
              const data = JSON.parse(fs.readFileSync(coveragePath, 'utf8'));
              const t = data.total;
              coverageSection = [
                '', '### üìä Coverage',
                '| Metric | Covered | Total | % |',
                '|--------|---------|-------|---|',
                `| Lines | ${t.lines.covered} | ${t.lines.total} | ${t.lines.pct}% |`,
                `| Functions | ${t.functions.covered} | ${t.functions.total} | ${t.functions.pct}% |`,
                `| Branches | ${t.branches.covered} | ${t.branches.total} | ${t.branches.pct}% |`,
              ].join('\n');
            }

            const allPassed = unitPassed && integrationPassed;
            const comment = [
              '## üß™ CI Test Results',
              '',
              '| Stage | Status |',
              '|-------|--------|',
              `| Unit Tests | ${unitEmoji} ${unitPassed ? 'Passed' : 'Failed'} |`,
              `| Integration Tests | ${integrationEmoji} ${integrationPassed ? 'Passed' : 'Failed'} |`,
              '| E2E Tests | ‚è≥ Pending |',
              coverageSection,
              '',
              allPassed ? '> E2E tests starting next...' : '> ‚ùå Tests failed - pipeline stopped.',
              '',
              `> Commit: \`${context.sha.substring(0, 7)}\` | [Artifacts](https://github.com/${context.repo.owner}/${context.repo.repo}/actions/runs/${context.runId})`,
            ].join('\n');

            const MARKER = '<!-- CI-TEST-RESULTS-COMMENT -->';
            const { data: comments } = await github.rest.issues.listComments({
              owner: context.repo.owner, repo: context.repo.repo, issue_number: context.issue.number,
            });
            const existing = comments.find(c => c.user.type === 'Bot' && c.body.includes(MARKER));

            if (existing) {
              await github.rest.issues.updateComment({
                owner: context.repo.owner, repo: context.repo.repo,
                comment_id: existing.id, body: MARKER + '\n' + comment
              });
            } else {
              await github.rest.issues.createComment({
                owner: context.repo.owner, repo: context.repo.repo,
                issue_number: context.issue.number, body: MARKER + '\n' + comment
              });
            }

      - name: "üì§ Upload build logs"
        if: always()
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02 # v4
        with:
          name: build-logs-${{ github.run_id }}
          path: |
            /tmp/lint-output.log
          retention-days: 14
          if-no-files-found: ignore

      - name: "üßπ Cleanup: stop postgres/redis containers, remove volumes and compose file"
        if: always()
        run: |
          echo "üßπ Cleaning up test containers..."
          docker stop loyalty_postgres_test loyalty_redis_test 2>/dev/null || true
          docker rm -f loyalty_postgres_test loyalty_redis_test 2>/dev/null || true
          docker volume rm loyalty_postgres_test_data 2>/dev/null || true
          rm -f docker-compose.test.yml || true
          echo "‚úÖ Cleanup complete"

  # Job 1D: E2E Tests (Conditional - only on main branch or PR to main)
  e2e-tests:
    name: "üé≠ E2E Tests"
    runs-on: self-hosted
    permissions:
      pull-requests: write  # For PR comments on test results
      contents: read
    env:
      COMPOSE_PROJECT_NAME: loyalty-e2e-tests

    # Prevent parallel E2E runs to avoid port conflicts with host network
    concurrency:
      group: e2e-tests
      cancel-in-progress: false

    needs: [validate-and-test]  # Sequential: runs after validation and tests pass
    timeout-minutes: 20  # Increased from 8: allows ~15min for 36 tests + 3-5min infrastructure setup
    if: (github.ref == 'refs/heads/main' || github.base_ref == 'main')
    outputs:
      e2e-passed: ${{ steps.e2e-results.outputs.passed }}

    steps:
      - name: "üì• Copy shared workspace & restore root/backend/frontend dependencies"
        run: |
          SHARED_WORKSPACE="/tmp/runner-cache/workspace/${{ github.run_id }}"
          if [ ! -d "$SHARED_WORKSPACE" ]; then
            echo "‚ùå Shared workspace not found at $SHARED_WORKSPACE"
            exit 1
          fi
          rsync -a --delete "$SHARED_WORKSPACE/" .
          echo "‚úÖ Workspace ready (stale files removed)"

          echo "üì¶ Restoring root node_modules (Playwright)..."
          cp -r /tmp/runner-cache/${{ env.CACHE_VERSION }}/root-node_modules/node_modules ./ || exit 1

          echo "üì¶ Restoring backend node_modules..."
          cp -r /tmp/runner-cache/${{ env.CACHE_VERSION }}/backend-node_modules/node_modules ./backend/ || exit 1

          echo "üì¶ Restoring frontend node_modules..."
          cp -r /tmp/runner-cache/${{ env.CACHE_VERSION }}/frontend-node_modules/node_modules ./frontend/ || exit 1

          echo "‚úÖ All dependencies restored"

      - name: "‚ö° Setup Node.js runtime environment"
        uses: actions/setup-node@395ad3262231945c25e8478fd5baf05154b1d79f # v6
        with:
          node-version: ${{ env.NODE_VERSION }}

      - name: "üßπ Cleanup E2E ports, validate Prisma client & remove stale volumes"
        run: |
          # Verify Node.js version
          echo "üîç Node.js: $(node --version) | npm: $(npm --version)"
          NODE_MAJOR=$(node --version | cut -d'.' -f1 | tr -d 'v')
          if [ "$NODE_MAJOR" -lt "${{ env.NODE_VERSION }}" ]; then
            echo "‚ùå Node.js version mismatch! Expected ${{ env.NODE_VERSION }}.x, got $(node --version)"
            exit 1
          fi

          echo "üßπ Cleaning up E2E ports (5436, 6381, 3201, 4202)..."
          for port in 5436 6381 3201 4202; do
            pid=$(lsof -ti:$port 2>/dev/null || true)
            if [ ! -z "$pid" ]; then
              echo "‚ö†Ô∏è Killing process on port $port (PID: $pid)"
              kill -9 $pid 2>/dev/null || true
            fi
          done
          sleep 2
          echo "‚úÖ Port cleanup completed"

          echo ""
          echo "üîç Validating Prisma client from shared workspace..."
          if [ ! -d "backend/src/generated/prisma" ]; then
            echo "‚ùå Prisma client not found - workspace preparation may have failed"
            exit 1
          fi
          echo "‚úÖ Prisma client validated"

          echo ""
          echo "üßπ Removing stale E2E database volumes..."
          docker volume rm loyalty_postgres_e2e_data loyalty_redis_e2e_data 2>/dev/null || true
          docker volume rm loyalty-e2e-tests_loyalty_postgres_e2e_data loyalty-e2e-tests_loyalty_redis_e2e_data 2>/dev/null || true
          echo "‚úÖ E2E environment prepared"

      - name: "üèóÔ∏è Build backend & frontend applications sequentially"
        run: |
          echo "üèóÔ∏è Building backend..."
          cd backend && npm run build && cd ..

          echo "üèóÔ∏è Building frontend..."
          cd frontend && npm run build && cd ..

          echo "‚úÖ Both applications built successfully"

      - name: "üê≥ Create Docker Compose config, start E2E stack & wait for services"
        working-directory: .
        env:
          DATABASE_URL: postgresql://loyalty:loyalty_password@localhost:5436/loyalty_db
          NODE_ENV: development
          # OAuth Configuration for E2E tests (from GitHub Secrets)
          GOOGLE_CLIENT_ID: ${{ secrets.GOOGLE_CLIENT_ID || 'test-google-not-configured' }}
          GOOGLE_CLIENT_SECRET: ${{ secrets.GOOGLE_CLIENT_SECRET || 'test-google-secret-not-configured' }}
          LINE_CHANNEL_ID: ${{ secrets.LINE_CHANNEL_ID || 'test-line-not-configured' }}
          LINE_CHANNEL_SECRET: ${{ secrets.LINE_CHANNEL_SECRET || 'test-line-secret-not-configured' }}
          SLIPOK_API_KEY: ${{ secrets.SLIPOK_API_KEY || 'test-slipok-not-configured' }}
          SLIPOK_BRANCH_ID: ${{ secrets.SLIPOK_BRANCH_ID || 'test-branch-not-configured' }}
        run: |
          echo "üöÄ Starting isolated application stack for E2E tests..."

          # Create E2E admin config (overwrites default for E2E testing)
          # This gets baked into the Docker image during build
          echo "üìù Creating E2E admin configuration..."
          mkdir -p backend/config
          cat > backend/config/admins.json << 'ADMINS_EOF'
          {
            "adminEmails": ["e2e-admin@test.local"],
            "superAdminEmails": ["e2e-admin@test.local"],
            "description": "E2E test admin configuration - created by CI workflow"
          }
          ADMINS_EOF
          echo "‚úÖ E2E admin config created (will be included in Docker build)"

          # Create the E2E Docker Compose file with host networking
          echo "üìù Creating E2E Docker Compose configuration with host network..."
          cat > docker-compose.e2e.ci.yml << EOF
          services:
            postgres:
              image: postgres:15-alpine
              container_name: loyalty_postgres_e2e
              network_mode: host
              environment:
                POSTGRES_USER: loyalty
                POSTGRES_PASSWORD: loyalty_password
                POSTGRES_DB: loyalty_db
                PGPORT: 5436
              tmpfs:
                - /dev/shm:size=256m
              volumes:
                - loyalty_postgres_e2e_data:/var/lib/postgresql/data
              healthcheck:
                test: ["CMD-SHELL", "pg_isready -U loyalty -d loyalty_db -p 5436"]
                interval: 5s
                timeout: 5s
                retries: 5
                start_period: 10s

            redis:
              image: redis:7-alpine
              container_name: loyalty_redis_e2e
              network_mode: host
              command: redis-server --port 6381
              volumes:
                - loyalty_redis_e2e_data:/data
              healthcheck:
                test: ["CMD", "redis-cli", "-p", "6381", "ping"]
                interval: 5s
                timeout: 3s
                retries: 5

            backend:
              build:
                context: ./backend
                dockerfile: Dockerfile
                target: development
              container_name: loyalty_backend_e2e
              network_mode: host
              environment:
                NODE_ENV: development
                PORT: 4202
                DATABASE_URL: postgresql://loyalty:loyalty_password@localhost:5436/loyalty_db
                REDIS_URL: redis://localhost:6381
                JWT_SECRET: e2e-jwt-secret-for-testing-only-must-be-64-chars-minimum-xxxxxxx
                JWT_REFRESH_SECRET: e2e-refresh-secret-for-testing-only-must-be-64-chars-minimum-xxx
                SESSION_SECRET: e2e-session-secret-for-testing-only-min-32-chars
                FRONTEND_URL: http://localhost:3201
                BACKEND_URL: http://localhost:4202
                CORS_ORIGINS: "http://localhost:3201"
                # OAuth Configuration (from GitHub Secrets)
                GOOGLE_CLIENT_ID: ${GOOGLE_CLIENT_ID}
                GOOGLE_CLIENT_SECRET: ${GOOGLE_CLIENT_SECRET}
                GOOGLE_CALLBACK_URL: http://localhost:4202/api/oauth/google/callback
                LINE_CHANNEL_ID: ${LINE_CHANNEL_ID}
                LINE_CHANNEL_SECRET: ${LINE_CHANNEL_SECRET}
                LINE_CALLBACK_URL: http://localhost:4202/api/oauth/line/callback
              depends_on:
                postgres:
                  condition: service_healthy
                redis:
                  condition: service_healthy
              healthcheck:
                test: ["CMD-SHELL", "curl -f http://localhost:4202/api/health || exit 1"]
                interval: 10s
                timeout: 5s
                retries: 5
                start_period: 30s

            frontend:
              build:
                context: ./frontend
                dockerfile: Dockerfile
                target: development
              container_name: loyalty_frontend_e2e
              network_mode: host
              environment:
                NODE_ENV: development
                PORT: 3201
                VITE_API_URL: http://localhost:4202/api
              depends_on:
                backend:
                  condition: service_healthy
              healthcheck:
                test: ["CMD-SHELL", "curl -f http://localhost:3201 || exit 1"]
                interval: 10s
                timeout: 5s
                retries: 3

          volumes:
            loyalty_postgres_e2e_data:
              driver: local
            loyalty_redis_e2e_data:
              driver: local
          EOF
          
          echo "‚úÖ E2E Docker Compose configuration created"
          
          # Force remove any stale E2E containers by name (from previous runs with different project names)
          echo "üßπ Force removing any stale E2E containers..."
          docker rm -f loyalty_postgres_e2e loyalty_redis_e2e loyalty_backend_e2e loyalty_frontend_e2e 2>/dev/null || true

          # Also cleanup with docker compose (for volumes and networks)
          echo "üßπ Cleaning up E2E volumes and networks..."
          docker compose -p loyalty-e2e-tests -f docker-compose.e2e.ci.yml down -v --remove-orphans 2>/dev/null || true

          # Check for processes using E2E ports and kill them
          echo "üîç Checking for processes using E2E ports..."
          for port in 3201 4202 5436 6381; do
            pid=$(lsof -ti:$port 2>/dev/null || true)
            if [ ! -z "$pid" ]; then
              echo "‚ö†Ô∏è Found process $pid using port $port, terminating..."
              kill -9 $pid 2>/dev/null || true
              sleep 1
            fi
          done
          
          # Verify ports are free
          echo "‚úÖ Port cleanup completed"
          netstat -tlnp | grep -E ":320[1-9]|:420[2-9]|:543[6-9]|:638[1-9]" || echo "No conflicting ports found"
          
          # Start containers with --wait to ensure all services are healthy before continuing
          echo "üöÄ Starting E2E containers (with --wait for health checks)..."
          if docker compose -p loyalty-e2e-tests -f docker-compose.e2e.ci.yml up -d --build --wait --wait-timeout 300; then
            echo "‚úÖ All E2E containers are healthy and ready"
          else
            echo "‚ùå Docker containers failed to start or become healthy"
            echo "üìä Container status:"
            docker compose -p loyalty-e2e-tests -f docker-compose.e2e.ci.yml ps -a
            echo ""
            echo "üìÑ Backend container logs:"
            docker logs loyalty_backend_e2e 2>&1 | tail -100 || echo "No backend logs available"
            echo ""
            echo "üìÑ Frontend container logs:"
            docker logs loyalty_frontend_e2e 2>&1 | tail -100 || echo "No frontend logs available"
            echo ""
            echo "üìÑ PostgreSQL container logs:"
            docker logs loyalty_postgres_e2e 2>&1 | tail -50 || echo "No postgres logs available"
            echo ""
            echo "üìÑ Redis container logs:"
            docker logs loyalty_redis_e2e 2>&1 | tail -20 || echo "No redis logs available"
            exit 1
          fi

          echo "‚úÖ Isolated application stack is ready for E2E testing"
          echo "üåê Backend: http://localhost:4202/api/health"
          echo "üåê Frontend: http://localhost:3201"
          echo ""
          echo "üìä Container status:"
          docker compose -p loyalty-e2e-tests -f docker-compose.e2e.ci.yml ps

      - name: "üé≠ Execute Playwright E2E test suite against isolated stack"
        id: run-e2e-tests
        env:
          NODE_ENV: test
          DATABASE_URL: postgresql://loyalty:loyalty_password@localhost:5436/loyalty_db
          REDIS_URL: redis://localhost:6381
          BACKEND_URL: http://localhost:4202
          FRONTEND_URL: http://localhost:3201
          SKIP_PLAYWRIGHT_DOCKER_SETUP: "true"
          # GitHub Secrets for CI/CD environment validation test
          JWT_SECRET: ${{ secrets.JWT_SECRET }}
          JWT_REFRESH_SECRET: ${{ secrets.JWT_REFRESH_SECRET }}
          SESSION_SECRET: ${{ secrets.SESSION_SECRET }}
          GOOGLE_CLIENT_ID: ${{ secrets.GOOGLE_CLIENT_ID }}
          GOOGLE_CLIENT_SECRET: ${{ secrets.GOOGLE_CLIENT_SECRET }}
          LINE_CHANNEL_ID: ${{ secrets.LINE_CHANNEL_ID }}
          LINE_CHANNEL_SECRET: ${{ secrets.LINE_CHANNEL_SECRET }}
        run: |
          echo "üé≠ Running E2E tests with Playwright on isolated environment..."
          echo "üåê Testing against Backend: http://localhost:4202"
          echo "üåê Testing against Frontend: http://localhost:3201"

          # Verify Playwright is available
          if [ ! -d "node_modules/@playwright" ]; then
            echo "‚ùå @playwright/test not found in node_modules"
            echo "üìÇ Root node_modules contents:"
            ls -la node_modules/ 2>&1 | head -20 || echo "node_modules directory not found"
            exit 1
          fi

          echo "‚úÖ @playwright/test found in node_modules"

          # Install Playwright browsers if needed
          echo "üì• Installing Playwright browsers..."
          npx playwright install --with-deps chromium

          # Verify Playwright installation
          echo "üîç Verifying Playwright installation..."
          npx playwright --version

          # Quick health check before tests
          echo "üè• Final health check before tests..."
          curl -sf http://localhost:4202/api/health > /dev/null && echo "‚úÖ Backend healthy" || { echo "‚ùå Backend health check failed"; exit 1; }
          curl -sf http://localhost:3201 > /dev/null && echo "‚úÖ Frontend healthy" || { echo "‚ùå Frontend health check failed"; exit 1; }

          # Run all E2E tests (API + browser projects) against isolated environment
          echo "üé≠ Running E2E tests (api + browser projects) - failures will BLOCK the pipeline..."
          npx playwright test --project=api --project=browser

      - name: "üóÑÔ∏è Verify database migration rollback safety (non-blocking)"
        run: |
          echo "üóÑÔ∏è Checking migration rollback safety..."
          if [ -f "./scripts/migration-rollback-safety.sh" ]; then
            ./scripts/migration-rollback-safety.sh check || echo "‚ö†Ô∏è Migration rollback check failed (non-blocking in CI)"
          else
            echo "‚ö†Ô∏è Migration rollback safety script not found - skipping"
          fi

      - name: "üìä Record E2E test results"
        id: e2e-results
        if: steps.run-e2e-tests.outcome == 'success'
        run: echo "passed=true" >> $GITHUB_OUTPUT

      - name: "üìä Write E2E test summary to job summary"
        if: always()
        run: |
          # Determine status directly from run-e2e-tests outcome
          if [ "${{ steps.run-e2e-tests.outcome }}" == "success" ]; then
            E2E_STATUS="‚úÖ Passed"
            STATUS_MSG="All E2E tests completed successfully!"
          else
            E2E_STATUS="‚ùå Failed"
            STATUS_MSG="Some E2E tests failed. Check the Allure report for details."
          fi

          echo "## üé≠ E2E Test Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Test Suite | Status |" >> $GITHUB_STEP_SUMMARY
          echo "|:-----------|:-------|" >> $GITHUB_STEP_SUMMARY
          echo "| Playwright E2E Tests | $E2E_STATUS |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "> $STATUS_MSG" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          # Test artifacts info
          echo "## üì• E2E Test Artifacts" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "E2E test results are available as workflow artifacts for 7 days." >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Artifact | Description |" >> $GITHUB_STEP_SUMMARY
          echo "|:---------|:------------|" >> $GITHUB_STEP_SUMMARY
          echo "| \`allure-results-e2e-*\` | Allure test results for report generation |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          # Link to test reports page (use run_number for direct link)
          echo "## üîó View Reports" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "üìä [View Allure Report](https://jwinut.github.io/loyalty-app/test-reports/${{ github.run_number }}/)" >> $GITHUB_STEP_SUMMARY
          echo "üìà [View Coverage Report](https://jwinut.github.io/loyalty-app/test-reports/${{ github.run_number }}/coverage/lcov-report/)" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

      - name: "üì§ Upload E2E Allure results to GitHub artifacts"
        if: always()
        uses: actions/upload-artifact@330a01c490aca151604b8cf639adc76d48f6c5d4 # v5
        with:
          name: allure-results-e2e-${{ github.run_id }}
          path: allure-results/
          retention-days: 7
          if-no-files-found: warn

      - name: "üí¨ Post E2E test results comment on pull request"
        if: always() && github.event_name == 'pull_request'
        uses: actions/github-script@ed597411d8f924073f98dfc5c65a23a2325f34cd # v8
        continue-on-error: true
        with:
          script: |
            const e2eResult = '${{ steps.run-e2e-tests.outcome }}';
            const e2ePassed = e2eResult === 'success';

            const statusEmoji = e2ePassed ? '‚úÖ' : '‚ùå';
            const statusText = e2ePassed ? 'Passed' : 'Failed';

            const comment = [
              '## üß™ CI Test Results',
              '',
              '| Stage | Status |',
              '|-------|--------|',
              '| Unit Tests | ‚úÖ Passed |',
              '| Integration Tests | ‚úÖ Passed |',
              `| E2E Tests | ${statusEmoji} ${statusText} |`,
              '',
              '### üé≠ E2E Details',
              '| Test Suite | Status |',
              '|:-----------|:-------|',
              `| Playwright E2E | ${statusEmoji} ${statusText} |`,
              '',
              e2ePassed
                ? '> ‚úÖ All tests passed! Ready for build and deployment.'
                : '> ‚ùå E2E tests failed - review test results.',
              '',
              `> Commit: \`${context.sha.substring(0, 7)}\` | [View Artifacts](https://github.com/${context.repo.owner}/${context.repo.repo}/actions/runs/${context.runId})`,
              '',
              'üìä [View Allure Report](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})',
            ].join('\n');

            const COMMENT_MARKER = '<!-- CI-TEST-RESULTS-COMMENT -->';
            const fullComment = COMMENT_MARKER + '\n' + comment;

            const { data: comments } = await github.rest.issues.listComments({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
            });

            const botComment = comments.find(c =>
              c.user.type === 'Bot' && c.body.includes(COMMENT_MARKER)
            );

            if (botComment) {
              await github.rest.issues.updateComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                comment_id: botComment.id,
                body: fullComment
              });
            } else {
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: context.issue.number,
                body: fullComment
              });
            }

      # =============================================================================
      # PERFORMANCE TESTS (after E2E, reusing containers)
      # =============================================================================
      - name: "üì¶ Install k6 for load testing (if needed)"
        if: steps.run-e2e-tests.outcome == 'success'
        run: |
          if ! command -v k6 &> /dev/null; then
            echo "üì¶ Installing k6..."
            sudo gpg -k
            sudo gpg --no-default-keyring --keyring /usr/share/keyrings/k6-archive-keyring.gpg \
              --keyserver hkp://keyserver.ubuntu.com:80 \
              --recv-keys C5AD17C747E3415A3642D57D77C6C491D6AC1D69
            echo "deb [signed-by=/usr/share/keyrings/k6-archive-keyring.gpg] https://dl.k6.io/deb stable main" \
              | sudo tee /etc/apt/sources.list.d/k6.list
            sudo apt-get update && sudo apt-get install k6 -y
          else
            echo "‚úÖ k6 already installed: $(k6 version)"
          fi

      - name: "‚ö° Run performance tests"
        id: perf-tests
        if: steps.run-e2e-tests.outcome == 'success'
        continue-on-error: true
        env:
          DATABASE_URL: postgresql://loyalty:loyalty_password@localhost:5436/loyalty_db
          BACKEND_URL: http://localhost:4202
        working-directory: ./backend
        run: |
          mkdir -p benchmark-results

          echo "üß™ Running database benchmarks..."
          npm run test:perf:db 2>&1 | tee benchmark-results/db-benchmark.log || echo "‚ö†Ô∏è DB benchmarks had failures"

          echo "üß™ Running API benchmarks..."
          npm run test:perf:api 2>&1 | tee benchmark-results/api-benchmark.log || echo "‚ö†Ô∏è API benchmarks had failures"

          echo "üöÄ Running k6 load tests..."
          k6 run src/__tests__/performance/k6/load-test.js \
            --out json=benchmark-results/k6-results.json \
            --summary-export=benchmark-results/k6-summary.json 2>&1 | tee benchmark-results/k6.log || echo "‚ö†Ô∏è k6 tests had failures"

      - name: "üì§ Upload performance benchmark results"
        if: always() && steps.perf-tests.outcome != 'skipped'
        uses: actions/upload-artifact@330a01c490aca151604b8cf639adc76d48f6c5d4
        with:
          name: benchmark-results-${{ github.run_id }}
          path: backend/benchmark-results/
          retention-days: 30
          if-no-files-found: warn

      - name: "üìä Write performance test summary"
        if: always() && steps.perf-tests.outcome != 'skipped'
        run: |
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## ‚ö° Performance Test Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          # Check if k6 summary exists
          if [ -f "backend/benchmark-results/k6-summary.json" ]; then
            echo "### üöÄ k6 Load Test Summary" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY

            # Extract key metrics from k6 summary (k6 --summary-export format)
            HTTP_REQS=$(jq -r '.metrics.http_reqs.count // "N/A"' backend/benchmark-results/k6-summary.json 2>/dev/null || echo "N/A")
            HTTP_REQ_DURATION_AVG=$(jq -r '.metrics.http_req_duration.avg // "N/A"' backend/benchmark-results/k6-summary.json 2>/dev/null || echo "N/A")
            HTTP_REQ_DURATION_P95=$(jq -r '.metrics.http_req_duration["p(95)"] // "N/A"' backend/benchmark-results/k6-summary.json 2>/dev/null || echo "N/A")
            HTTP_REQ_FAILED=$(jq -r '.metrics.http_req_failed.rate // "N/A"' backend/benchmark-results/k6-summary.json 2>/dev/null || echo "N/A")
            ITERATIONS=$(jq -r '.metrics.iterations.count // "N/A"' backend/benchmark-results/k6-summary.json 2>/dev/null || echo "N/A")

            echo "| Metric | Value |" >> $GITHUB_STEP_SUMMARY
            echo "|:-------|------:|" >> $GITHUB_STEP_SUMMARY
            echo "| Total HTTP Requests | $HTTP_REQS |" >> $GITHUB_STEP_SUMMARY
            echo "| Avg Response Time | ${HTTP_REQ_DURATION_AVG}ms |" >> $GITHUB_STEP_SUMMARY
            echo "| P95 Response Time | ${HTTP_REQ_DURATION_P95}ms |" >> $GITHUB_STEP_SUMMARY
            echo "| Failed Request Rate | ${HTTP_REQ_FAILED} |" >> $GITHUB_STEP_SUMMARY
            echo "| Total Iterations | $ITERATIONS |" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
          else
            echo "‚ö†Ô∏è k6 summary not available" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
          fi

          # Add Jest benchmark results if available
          if [ -f "backend/benchmark-results/db-benchmark.log" ]; then
            echo "### üóÑÔ∏è Database Benchmark" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "<details>" >> $GITHUB_STEP_SUMMARY
            echo "<summary>Click to expand</summary>" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo '```' >> $GITHUB_STEP_SUMMARY
            # Extract benchmark results (lines with timing info)
            grep -E "(PASS|FAIL|‚úì|‚úï|ms|benchmark)" backend/benchmark-results/db-benchmark.log | tail -30 >> $GITHUB_STEP_SUMMARY || echo "No benchmark data" >> $GITHUB_STEP_SUMMARY
            echo '```' >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "</details>" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
          fi

          if [ -f "backend/benchmark-results/api-benchmark.log" ]; then
            echo "### üåê API Benchmark" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "<details>" >> $GITHUB_STEP_SUMMARY
            echo "<summary>Click to expand</summary>" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo '```' >> $GITHUB_STEP_SUMMARY
            grep -E "(PASS|FAIL|‚úì|‚úï|ms|benchmark)" backend/benchmark-results/api-benchmark.log | tail -30 >> $GITHUB_STEP_SUMMARY || echo "No benchmark data" >> $GITHUB_STEP_SUMMARY
            echo '```' >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "</details>" >> $GITHUB_STEP_SUMMARY
          fi

          echo "" >> $GITHUB_STEP_SUMMARY
          echo "> üì• Full benchmark results available in workflow artifacts" >> $GITHUB_STEP_SUMMARY

      - name: "üì§ Capture container logs on failure"
        if: failure()
        run: |
          mkdir -p container-logs
          echo "üìÑ Capturing E2E container logs for debugging..."
          docker logs loyalty_backend_e2e > container-logs/backend.log 2>&1 || echo "No backend logs" > container-logs/backend.log
          docker logs loyalty_frontend_e2e > container-logs/frontend.log 2>&1 || echo "No frontend logs" > container-logs/frontend.log
          docker logs loyalty_postgres_e2e > container-logs/postgres.log 2>&1 || echo "No postgres logs" > container-logs/postgres.log
          docker logs loyalty_redis_e2e > container-logs/redis.log 2>&1 || echo "No redis logs" > container-logs/redis.log
          echo "‚úÖ Container logs captured"

      - name: "üì§ Upload container logs"
        if: failure()
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02 # v4
        with:
          name: container-logs-${{ github.run_id }}
          path: container-logs/
          retention-days: 7
          if-no-files-found: ignore

      - name: "üßπ Teardown E2E Docker containers, volumes & generated config"
        if: always()
        run: |
          echo "üßπ Cleaning up isolated E2E environment..."
          docker compose -p loyalty-e2e-tests -f docker-compose.e2e.ci.yml down -v --remove-orphans || true

          # SAFETY: Only remove test-specific volumes, NEVER docker system prune
          # docker system prune can destroy production containers/volumes!
          echo "üßπ Removing E2E volumes to prevent future migration state issues..."
          docker volume rm loyalty_postgres_e2e_data loyalty_redis_e2e_data 2>/dev/null || true
          docker volume rm loyalty-e2e-tests_loyalty_postgres_e2e_data loyalty-e2e-tests_loyalty_redis_e2e_data 2>/dev/null || true

          rm -f docker-compose.e2e.ci.yml || true
          echo "‚úÖ Isolated E2E environment cleaned up"

  # =============================================================================
  # PHASE 2: BUILD & DEPLOYMENT PREPARATION (2-3 minutes, only on main)
  # =============================================================================
  
  # Job 2A: Build validation (only for main branch, after all tests)
  build-validation:
    name: "üèóÔ∏è Build Validation & Docker Images"
    runs-on: self-hosted
    needs: [validate-and-test, e2e-tests]
    if: github.ref == 'refs/heads/main' && always() && needs.validate-and-test.outputs.security-passed == 'true' && needs.validate-and-test.outputs.unit-tests-passed == 'true' && needs.validate-and-test.outputs.integration-tests-passed == 'true' && needs.e2e-tests.outputs.e2e-passed == 'true'
    timeout-minutes: 15
    outputs:
      build-passed: ${{ steps.build-results.outputs.passed }}
      backend-image: ${{ steps.docker-build.outputs.backend_image }}
      frontend-image: ${{ steps.docker-build.outputs.frontend_image }}
      images-ready: ${{ steps.docker-build.outputs.images_ready }}
    
    steps:
      - name: "üßπ Clean workspace, setup cache directories & checkout code"
        run: |
          echo "üßπ Cleaning workspace at ${{ github.workspace }}..."
          cd ${{ github.workspace }}

          # Force clean problematic directories with sudo
          sudo rm -rf frontend/dist backend/dist frontend/build backend/build 2>/dev/null || true
          sudo rm -rf frontend/.next backend/.next 2>/dev/null || true
          sudo rm -rf node_modules frontend/node_modules backend/node_modules 2>/dev/null || true

          # Clean git repository state
          if [ -d ".git" ]; then
            sudo git clean -xffd 2>/dev/null || true
            git reset --hard 2>/dev/null || true
          fi

          # Fix ownership
          sudo chown -R $USER:$USER . 2>/dev/null || true

          # Setup cache directories
          mkdir -p /tmp/runner-cache/${{ env.CACHE_VERSION }}/{npm,backend-node_modules,frontend-node_modules}
          echo "‚úÖ Workspace cleaned and cache directories prepared"

      - name: "üì• Checkout code"
        uses: actions/checkout@8e8c483db84b4bee98b60c0593521ed34d9990e8 # v6
        with:
          fetch-depth: 1
          clean: false

      - name: "‚ö° Setup Node.js"
        uses: actions/setup-node@395ad3262231945c25e8478fd5baf05154b1d79f # v6
        with:
          node-version: ${{ env.NODE_VERSION }}

      - name: "üì¶ Restore/install backend & frontend dependencies from cache"
        run: |
          # Verify Node.js version
          echo "üîç Node.js: $(node --version) | npm: $(npm --version)"
          NODE_MAJOR=$(node --version | cut -d'.' -f1 | tr -d 'v')
          if [ "$NODE_MAJOR" -lt "${{ env.NODE_VERSION }}" ]; then
            echo "‚ùå Node.js version mismatch! Expected ${{ env.NODE_VERSION }}.x, got $(node --version)"
            exit 1
          fi

          # Backend dependencies
          BACKEND_CACHE="/tmp/runner-cache/${{ env.CACHE_VERSION }}/backend-node_modules"
          if [ -d "$BACKEND_CACHE/node_modules" ]; then
            echo "‚úÖ Restoring backend node_modules from cache..."
            cp -r "$BACKEND_CACHE/node_modules" ./backend/
          else
            echo "üì¶ Installing backend dependencies..."
            cd backend && npm ci --cache /tmp/runner-cache/${{ env.CACHE_VERSION }}/npm --prefer-offline --include=dev
            flock -w 60 "$BACKEND_CACHE/.flock" bash -c "rm -rf '$BACKEND_CACHE/node_modules' && cp -r node_modules '$BACKEND_CACHE/'"
            cd ..
          fi

          # Frontend dependencies
          FRONTEND_CACHE="/tmp/runner-cache/${{ env.CACHE_VERSION }}/frontend-node_modules"
          if [ -d "$FRONTEND_CACHE/node_modules" ]; then
            echo "‚úÖ Restoring frontend node_modules from cache..."
            cp -r "$FRONTEND_CACHE/node_modules" ./frontend/
          else
            echo "üì¶ Installing frontend dependencies..."
            cd frontend && npm ci --cache /tmp/runner-cache/${{ env.CACHE_VERSION }}/npm --prefer-offline
            flock -w 60 "$FRONTEND_CACHE/.flock" bash -c "rm -rf '$FRONTEND_CACHE/node_modules' && cp -r node_modules '$FRONTEND_CACHE/'"
            cd ..
          fi
          echo "‚úÖ All dependencies ready"

      - name: "üîß Generate Prisma client & build backend/frontend sequentially"
        run: |
          echo "üîß Generating Prisma client..."
          cd backend && npm run db:generate && cd ..

          echo "üèóÔ∏è Building backend (production)..."
          cd backend && npm run build:prod && cd ..

          echo "üèóÔ∏è Building frontend..."
          cd frontend && npm run build && cd ..

          echo "‚úÖ Prisma generated and both applications built successfully"

      - name: "‚úÖ Verify build artifacts (backend/frontend dist directories)"
        run: |
          echo "üîç Verifying build outputs..."
          [ -d "backend/dist" ] || { echo "‚ùå backend/dist missing"; exit 1; }
          [ -d "frontend/dist" ] || { echo "‚ùå frontend/dist missing"; exit 1; }
          [ -f "backend/dist/index.js" ] || { echo "‚ùå backend/dist/index.js missing"; exit 1; }
          [ -f "frontend/dist/index.html" ] || { echo "‚ùå frontend/dist/index.html missing"; exit 1; }
          echo "‚úÖ All build artifacts verified"
      
      - name: "üê≥ Build production Docker images & tag with commit SHA"
        id: docker-build
        env:
          # Provide dummy environment variables for build-time validation
          # Real secrets will be used in production-deployment job
          NODE_ENV: production
          LOG_LEVEL: info
          CORS_ORIGINS: "https://loyalty.saichon.com"
          JWT_SECRET: "dummy-build-validation-secret-must-be-64-chars-minimum-xxxxxx"
          JWT_REFRESH_SECRET: "dummy-build-validation-refresh-secret-must-be-64-chars-minimum-xx"
          SESSION_SECRET: "dummy-build-validation-session-secret-min-32-chars"
          DATABASE_URL: "postgresql://dummy:dummy@dummy:5432/dummy"
          REDIS_URL: "redis://redis:6379"
          FRONTEND_URL: "https://loyalty.saichon.com"
          BACKEND_URL: "https://loyalty.saichon.com/api"
          VITE_API_URL: "https://loyalty.saichon.com/api"
          GOOGLE_CLIENT_ID: "dummy-google-client-id"
          GOOGLE_CLIENT_SECRET: "dummy-google-client-secret"
          GOOGLE_CALLBACK_URL: "https://loyalty.saichon.com/api/oauth/google/callback"
          LINE_CHANNEL_ID: "dummy-line-channel-id"
          LINE_CHANNEL_SECRET: "dummy-line-channel-secret"
          LINE_CALLBACK_URL: "https://loyalty.saichon.com/api/oauth/line/callback"
          TRANSLATION_FEATURE_ENABLED: "false"
          LOYALTY_USERNAME: "dummy-loyalty-user"
          LOYALTY_PASSWORD: "dummy-loyalty-password"
        run: |
          echo "üê≥ Building production Docker images with BuildKit optimization..."

          # Enable BuildKit for faster builds
          export DOCKER_BUILDKIT=1
          export COMPOSE_DOCKER_CLI_BUILD=1
          export BUILDKIT_INLINE_CACHE=1

          # Validate Docker Compose configuration
          echo "üîç Validating Docker Compose configuration..."
          docker compose -f docker-compose.yml -f docker-compose.prod.yml config > /dev/null
          echo "‚úÖ Configuration validated"

          # Build images once with production target
          echo "üèóÔ∏è Building Docker images (production runner stage)..."
          docker compose -f docker-compose.yml -f docker-compose.prod.yml build \
            --build-arg BUILDKIT_INLINE_CACHE=1 \
            --parallel

          # Tag images with commit SHA for deployment tracking
          echo "üè∑Ô∏è Tagging images with commit SHA..."
          COMMIT_SHA="${{ github.sha }}"
          SHORT_SHA="${COMMIT_SHA:0:7}"

          # Tag images with commit SHA (images are already built as loyalty-app-backend:latest)
          docker tag loyalty-app-backend:latest loyalty-app-backend:$COMMIT_SHA
          docker tag loyalty-app-backend:latest loyalty-app-backend:$SHORT_SHA
          echo "‚úÖ Backend image tagged: $COMMIT_SHA, $SHORT_SHA, latest"

          docker tag loyalty-app-frontend:latest loyalty-app-frontend:$COMMIT_SHA
          docker tag loyalty-app-frontend:latest loyalty-app-frontend:$SHORT_SHA
          echo "‚úÖ Frontend image tagged: $COMMIT_SHA, $SHORT_SHA, latest"

          # Verify images exist
          echo "üîç Verifying tagged images..."
          docker images | grep -E "loyalty-app-(backend|frontend)" | grep -E "$SHORT_SHA|latest"

          # Quick smoke test - bypass entrypoint to verify runtime and build artifacts
          echo "üß™ Running smoke tests..."

          # Backend: Verify Node.js and compiled production code exist
          if docker run --rm --entrypoint sh loyalty-app-backend:$SHORT_SHA -c "node --version && test -f /app/dist/index.js" >/dev/null 2>&1; then
            NODE_VERSION=$(docker run --rm --entrypoint node loyalty-app-backend:$SHORT_SHA --version 2>/dev/null || echo "unknown")
            echo "‚úÖ Backend smoke test passed ($NODE_VERSION, dist/index.js verified)"
          else
            echo "‚ùå Backend smoke test failed - Node.js or dist/index.js missing"
            exit 1
          fi

          # Frontend: Verify Node.js and package.json exist (uses development stage with Vite)
          if docker run --rm --entrypoint sh loyalty-app-frontend:$SHORT_SHA -c "node --version && test -f /app/package.json" >/dev/null 2>&1; then
            NODE_VERSION=$(docker run --rm --entrypoint node loyalty-app-frontend:$SHORT_SHA --version 2>/dev/null || echo "unknown")
            echo "‚úÖ Frontend smoke test passed ($NODE_VERSION, package.json verified)"
          else
            echo "‚ùå Frontend smoke test failed - Node.js or package.json missing"
            exit 1
          fi

          # Output image tags for deployment job
          echo "images_ready=true" >> $GITHUB_OUTPUT
          echo "backend_image=loyalty-app-backend:$COMMIT_SHA" >> $GITHUB_OUTPUT
          echo "frontend_image=loyalty-app-frontend:$COMMIT_SHA" >> $GITHUB_OUTPUT

          echo "‚úÖ Docker images built, tagged, and ready for deployment"
          echo "üì¶ Backend: loyalty-app-backend:$COMMIT_SHA"
          echo "üì¶ Frontend: loyalty-app-frontend:$COMMIT_SHA"
      
      - name: "üìä Record build validation results (passed status)"
        id: build-results
        run: |
          echo "‚úÖ Build validation completed successfully"
          echo "passed=true" >> $GITHUB_OUTPUT

  # =============================================================================
  # PHASE 3A: DEVELOPMENT DEPLOYMENT (only on develop branch, auto-deploy)
  # No approval needed - deploys to port 5001 for testing
  # =============================================================================

  development-deployment:
    name: "üß™ Development Deployment"
    runs-on: self-hosted
    environment: development
    needs: [validate-and-test]
    if: |
      github.ref == 'refs/heads/develop' &&
      needs.validate-and-test.outputs.security-passed == 'true' &&
      needs.validate-and-test.outputs.unit-tests-passed == 'true' &&
      needs.validate-and-test.outputs.integration-tests-passed == 'true'
    timeout-minutes: 10
    concurrency:
      group: dev-deployment
      cancel-in-progress: false  # Queue deployments - never cancel mid-deployment
    env:
      DEPLOY_PATH: /home/nut/loyalty-app-develop

    steps:
      - name: "üìä Pre-deployment validation"
        run: |
          echo "üîç Development deployment checks..."
          echo "Branch: ${{ github.ref_name }}"
          echo "Commit: ${{ github.sha }}"
          echo "Security: ${{ needs.validate-and-test.outputs.security-passed }}"
          echo "Unit Tests: ${{ needs.validate-and-test.outputs.unit-tests-passed }}"
          echo "Integration Tests: ${{ needs.validate-and-test.outputs.integration-tests-passed }}"
          echo "‚úÖ All checks passed - proceeding with development deployment"

      - name: "üì• Code deployment"
        run: |
          echo "üì• Deploying code to development environment..."

          DEPLOY_DIR="${DEPLOY_PATH:-/home/nut/loyalty-app-develop}"

          if [ -d "$DEPLOY_DIR/.git" ]; then
            echo "üì• Updating existing repository..."
            cd "$DEPLOY_DIR"

            # Show current state
            BEFORE_COMMIT=$(git rev-parse --short HEAD 2>/dev/null || echo "none")
            echo "üìç Current commit: $BEFORE_COMMIT"
            echo "üéØ Target commit:  ${{ github.sha }}"

            # Clean any local changes
            git clean -fd 2>/dev/null || true
            git reset --hard HEAD 2>/dev/null || true

            # Fetch and checkout the specific commit
            git fetch --depth 1 origin ${{ github.sha }}
            git checkout ${{ github.sha }}
          else
            echo "üì¶ Fresh clone..."
            mkdir -p "$(dirname "$DEPLOY_DIR")"
            git clone --depth 1 \
              https://x-access-token:${{ secrets.GITHUB_TOKEN }}@github.com/${{ github.repository }}.git \
              "$DEPLOY_DIR"
            cd "$DEPLOY_DIR"
            git fetch --depth 1 origin ${{ github.sha }}
            git checkout ${{ github.sha }}
          fi

          # Verify checkout succeeded
          AFTER_COMMIT=$(git rev-parse HEAD)
          TARGET_SHA="${{ github.sha }}"

          if [ "$AFTER_COMMIT" != "$TARGET_SHA" ]; then
            echo "‚ùå ERROR: Checkout verification failed!"
            echo "   Expected: $TARGET_SHA"
            echo "   Got:      $AFTER_COMMIT"
            exit 1
          fi

          echo ""
          echo "‚úÖ Code deployment completed"
          echo "   Deployed SHA: $AFTER_COMMIT"

      - name: "üîß Environment configuration"
        env:
          # Secrets from 'development' environment (no DEV_ prefix needed)
          JWT_SECRET: ${{ secrets.JWT_SECRET }}
          JWT_REFRESH_SECRET: ${{ secrets.JWT_REFRESH_SECRET }}
          SESSION_SECRET: ${{ secrets.SESSION_SECRET }}
          GOOGLE_CLIENT_ID: ${{ secrets.GOOGLE_CLIENT_ID }}
          GOOGLE_CLIENT_SECRET: ${{ secrets.GOOGLE_CLIENT_SECRET }}
          LINE_CHANNEL_ID: ${{ secrets.LINE_CHANNEL_ID }}
          LINE_CHANNEL_SECRET: ${{ secrets.LINE_CHANNEL_SECRET }}
          SMTP_HOST: ${{ vars.SMTP_HOST }}
          SMTP_PORT: ${{ vars.SMTP_PORT }}
          SMTP_USER: ${{ secrets.SMTP_USER }}
          SMTP_PASS: ${{ secrets.SMTP_PASS }}
          SMTP_FROM: ${{ secrets.SMTP_FROM }}
          IMAP_HOST: ${{ vars.IMAP_HOST }}
          IMAP_PORT: ${{ vars.IMAP_PORT }}
          SLIPOK_API_KEY: ${{ secrets.SLIPOK_API_KEY }}
          SLIPOK_BRANCH_ID: ${{ secrets.SLIPOK_BRANCH_ID }}
        run: |
          echo "üîß Configuring development environment..."

          DEPLOY_DIR="${DEPLOY_PATH:-/home/nut/loyalty-app-develop}"
          cd "$DEPLOY_DIR"

          # Create .env.development file for development with GitHub Secrets
          cat > .env.development << EOF
          # Development Environment - Auto-generated by GitHub Actions
          NODE_ENV=development

          # URLs (Development) - use deployed dev domain for CORS consistency
          FRONTEND_URL=https://loyalty-dev.saichon.com
          BACKEND_URL=https://loyalty-dev.saichon.com/api
          VITE_API_URL=/api
          VITE_TRANSLATION_ENABLED=false

          # Internal ports
          BACKEND_PORT=4000
          FRONTEND_PORT=3000

          # Database & Redis
          DATABASE_URL=postgresql://loyalty_dev:loyalty_dev_pass@postgres:5432/loyalty_dev_db
          REDIS_URL=redis://redis:6379

          # Security
          JWT_SECRET=${JWT_SECRET}
          JWT_REFRESH_SECRET=${JWT_REFRESH_SECRET}
          SESSION_SECRET=${SESSION_SECRET}

          # OAuth
          GOOGLE_CLIENT_ID=${GOOGLE_CLIENT_ID}
          GOOGLE_CLIENT_SECRET=${GOOGLE_CLIENT_SECRET}
          GOOGLE_CALLBACK_URL=https://loyalty-dev.saichon.com/api/oauth/google/callback
          LINE_CHANNEL_ID=${LINE_CHANNEL_ID}
          LINE_CHANNEL_SECRET=${LINE_CHANNEL_SECRET}
          LINE_CALLBACK_URL=https://loyalty-dev.saichon.com/api/oauth/line/callback

          # Email Service (SMTP)
          SMTP_HOST=${SMTP_HOST}
          SMTP_PORT=${SMTP_PORT}
          SMTP_USER=${SMTP_USER}
          SMTP_PASS=${SMTP_PASS}
          SMTP_FROM=${SMTP_FROM}

          # Email Service (IMAP - for delivery verification)
          IMAP_HOST=${IMAP_HOST}
          IMAP_PORT=${IMAP_PORT}
          IMAP_USER=${SMTP_USER}
          IMAP_PASS=${SMTP_PASS}

          # SlipOK API (Slip Verification)
          SLIPOK_API_KEY=${SLIPOK_API_KEY}
          SLIPOK_BRANCH_ID=${SLIPOK_BRANCH_ID}

          # Azure Translation
          TRANSLATION_FEATURE_ENABLED=false

          # Development settings
          LOG_LEVEL=debug
          CORS_ORIGINS=http://localhost:3000,http://localhost:5001,http://127.0.0.1:3000,http://127.0.0.1:5001,https://loyalty-dev.saichon.com

          # Admin credentials (development only)
          LOYALTY_USERNAME=admin@dev.local
          LOYALTY_PASSWORD=admin123
          EOF

          # docker compose always reads .env; symlink to reuse dev config
          ln -sf .env.development .env

          echo "‚úÖ Development environment configured"

      - name: "üîç Pre-deployment port check (dev)"
        run: |
          echo "üîç Checking if required development ports are available..."

          DEPLOY_DIR="${DEPLOY_PATH:-/home/nut/loyalty-app-develop}"
          cd "$DEPLOY_DIR"

          # Development ports (from docker-compose.dev.yml)
          REQUIRED_PORTS=(5435 6380 5001)
          PORTS_IN_USE=()

          for port in "${REQUIRED_PORTS[@]}"; do
            if lsof -i ":$port" -sTCP:LISTEN -t >/dev/null 2>&1; then
              echo "‚ö†Ô∏è Port $port is in use:"
              lsof -i ":$port" -sTCP:LISTEN || true
              PORTS_IN_USE+=($port)
            else
              echo "‚úÖ Port $port is available"
            fi
          done

          if [ ${#PORTS_IN_USE[@]} -gt 0 ]; then
            echo ""
            echo "‚ö†Ô∏è Ports in use: ${PORTS_IN_USE[*]}"
            echo "üõë Stopping existing development containers..."
            docker compose -f docker-compose.yml -f docker-compose.dev.yml down --timeout 30 || true

            # Re-check ports after shutdown
            echo "üîç Re-checking ports after shutdown..."
            sleep 5
            STILL_IN_USE=()
            for port in "${PORTS_IN_USE[@]}"; do
              if lsof -i ":$port" -sTCP:LISTEN -t >/dev/null 2>&1; then
                STILL_IN_USE+=($port)
              fi
            done

            if [ ${#STILL_IN_USE[@]} -gt 0 ]; then
              echo "‚ùå WARNING: Ports still in use after shutdown: ${STILL_IN_USE[*]}"
              echo "Continuing with deployment - may fail if ports cannot be freed"
            else
              echo "‚úÖ All ports now available after shutdown"
            fi
          fi

          echo "‚úÖ Port check complete"

      - name: "üê≥ Deploy development services"
        run: |
          echo "üê≥ Deploying development services on port 5001..."

          DEPLOY_DIR="${DEPLOY_PATH:-/home/nut/loyalty-app-develop}"
          cd "$DEPLOY_DIR"

          # Build and start with dev configuration
          echo "üèóÔ∏è Building and starting development services..."
          docker compose -f docker-compose.yml -f docker-compose.dev.yml up -d --build

          echo "‚è≥ Waiting for services to start..."
          sleep 15

          echo "‚úÖ Development services deployed"

      - name: "üóÑÔ∏è Database migration"
        run: |
          echo "üóÑÔ∏è Waiting for backend migrations to complete..."

          DEPLOY_DIR="${DEPLOY_PATH:-/home/nut/loyalty-app-develop}"
          cd "$DEPLOY_DIR"

          # Wait for backend to be healthy (entrypoint.sh runs migrations)
          # Backend health check means migrations have completed successfully
          echo "‚è≥ Waiting for backend health check..."
          for i in {1..60}; do
            if docker compose -f docker-compose.yml -f docker-compose.dev.yml exec -T backend \
               curl -sf http://localhost:4000/api/health > /dev/null 2>&1; then
              echo "‚úÖ Backend is healthy (migrations complete)"
              break
            fi

            if [ $i -eq 60 ]; then
              echo "‚ùå Backend failed to become healthy after 2 minutes"
              echo "üìÑ Backend logs:"
              docker compose -f docker-compose.yml -f docker-compose.dev.yml logs --tail=50 backend
              exit 1
            fi

            echo "Waiting for backend... ($i/60)"
            sleep 2
          done

          # Verify migration status (read-only, no execution)
          echo "üîç Verifying migration status..."
          docker compose -f docker-compose.yml -f docker-compose.dev.yml exec -T backend \
            npx prisma migrate status

          echo "‚úÖ Database migration phase completed"

      - name: "üîç Verify database schema and stored procedures"
        run: |
          echo "üîç Verifying database schema and stored procedures..."
          DEPLOY_DIR="${DEPLOY_PATH:-/home/nut/loyalty-app-develop}"
          cd "$DEPLOY_DIR"

          # Wait for database to be ready and responsive
          # Note: Dev environment uses loyalty_dev user, not loyalty
          echo "‚è≥ Waiting for database to be fully ready..."
          DB_READY=false
          for i in {1..10}; do
            if docker compose -f docker-compose.yml -f docker-compose.dev.yml exec -T postgres psql -U loyalty_dev -d loyalty_dev_db -c "SELECT 1" >/dev/null 2>&1; then
              echo "‚úÖ Database connection verified"
              DB_READY=true
              break
            fi
            echo "  Attempt $i/10: Database not ready, waiting..."
            sleep 2
          done

          if [ "$DB_READY" != "true" ]; then
            echo "‚ùå Database failed to become ready after 10 attempts"
            echo "  Check postgres container logs for errors"
            exit 1
          fi

          # Verify critical tables exist
          echo "üìã Checking critical tables..."
          TABLES_CHECK=$(docker compose -f docker-compose.yml -f docker-compose.dev.yml exec -T postgres psql -U loyalty_dev -d loyalty_dev_db -t -c "
            SELECT string_agg(tablename, ',')
            FROM pg_tables
            WHERE schemaname = 'public'
            AND tablename IN ('users', 'coupons', 'user_coupons', 'tiers', 'user_loyalty', 'user_audit_log', 'surveys');
          " 2>&1 | tr -d ' \n')

          echo "  Raw tables check result: '$TABLES_CHECK'"

          # Check if the query failed entirely - this is a FATAL error
          if echo "$TABLES_CHECK" | grep -qiE "error|fatal|connection refused"; then
            echo "‚ùå Database query failed - deployment cannot continue"
            echo "  Error: $TABLES_CHECK"
            exit 1
          fi

          REQUIRED_TABLES="users,coupons,user_coupons,tiers,user_loyalty,user_audit_log,surveys"
          MISSING_TABLES=""
          for table in $(echo "$REQUIRED_TABLES" | tr ',' ' '); do
            if ! echo "$TABLES_CHECK" | grep -q "$table"; then
              MISSING_TABLES="$MISSING_TABLES $table"
            fi
          done

          if [ -n "$MISSING_TABLES" ]; then
            echo "‚ùå Missing tables:$MISSING_TABLES"
            echo "  Note: Tables may still be initializing. Check migration logs above."
            exit 1
          else
            echo "‚úÖ All critical tables exist"
          fi

          # Verify critical stored procedures exist
          echo "üìã Checking critical stored procedures..."
          FUNCTIONS_CHECK=$(docker compose -f docker-compose.yml -f docker-compose.dev.yml exec -T postgres psql -U loyalty_dev -d loyalty_dev_db -t -c "
            SELECT string_agg(proname, ',')
            FROM pg_proc p
            JOIN pg_namespace n ON p.pronamespace = n.oid
            WHERE n.nspname = 'public'
            AND proname IN (
              'assign_coupon_to_user',
              'redeem_coupon',
              'award_points',
              'recalculate_user_tier_by_nights'
            );
          " 2>&1 | tr -d ' \n')

          echo "  Raw functions check result: '$FUNCTIONS_CHECK'"

          # Check if the query failed entirely - this is a FATAL error
          if echo "$FUNCTIONS_CHECK" | grep -qiE "error|fatal|connection refused"; then
            echo "‚ùå Stored procedures query failed - deployment cannot continue"
            echo "  Error: $FUNCTIONS_CHECK"
            exit 1
          else
            REQUIRED_FUNCTIONS="assign_coupon_to_user,redeem_coupon,award_points,recalculate_user_tier_by_nights"
            MISSING_FUNCTIONS=""
            for func in $(echo "$REQUIRED_FUNCTIONS" | tr ',' ' '); do
              if ! echo "$FUNCTIONS_CHECK" | grep -q "$func"; then
                MISSING_FUNCTIONS="$MISSING_FUNCTIONS $func"
              fi
            done

            if [ -n "$MISSING_FUNCTIONS" ]; then
              echo "‚ùå Missing stored procedures:$MISSING_FUNCTIONS"
              echo "‚ö†Ô∏è Run migration to create missing stored procedures"
              exit 1
            else
              echo "‚úÖ All critical stored procedures exist"
            fi
          fi

          echo "‚úÖ Database schema verification completed"

      - name: "üè• Health check"
        run: |
          echo "üè• Checking development service health..."

          DEPLOY_DIR="${DEPLOY_PATH:-/home/nut/loyalty-app-develop}"

          # Check backend health
          for i in {1..30}; do
            if curl -f -s http://localhost:5001/api/health >/dev/null 2>&1; then
              echo "‚úÖ Backend health check passed"
              break
            fi
            echo "Waiting for backend... ($i/30)"
            sleep 2
          done

          # Check if frontend is responding
          if curl -f -s http://localhost:5001 >/dev/null 2>&1; then
            echo "‚úÖ Frontend health check passed"
          else
            echo "‚ö†Ô∏è Frontend may still be starting..."
          fi

          # Check email service configuration
          echo ""
          echo "üîç Checking email service configuration..."
          HEALTH_RESPONSE=$(curl -sf --max-time 10 http://localhost:5001/api/health 2>/dev/null || echo '{}')
          EMAIL_STATUS=$(echo "$HEALTH_RESPONSE" | jq -r '.services.email // "unknown"')
          case "$EMAIL_STATUS" in
            "configured")
              echo "‚úÖ Email service: Configured"
              ;;
            "not_configured")
              echo "‚ö†Ô∏è Email service: Not configured"
              ;;
            *)
              echo "‚ùì Email service: $EMAIL_STATUS"
              ;;
          esac

          # Show running containers (run from deploy dir to find .env.development)
          echo ""
          echo "üìä Running development containers:"
          cd "$DEPLOY_DIR"
          docker compose -f docker-compose.yml -f docker-compose.dev.yml ps

          echo ""
          echo "‚úÖ Development deployment completed successfully!"
          echo "üåê Development URL: http://localhost:5001"

      - name: "üßπ Cleanup development env files"
        if: always()
        run: |
          DEPLOY_DIR="${DEPLOY_PATH:-/home/nut/loyalty-app-develop}"
          cd "$DEPLOY_DIR"
          rm -f .env .env.development || true

  # =============================================================================
  # PHASE 3B: PRODUCTION DEPLOYMENT (only on main, after all tests pass)
  # Pipeline Order: Pre-validation ‚Üí Backup ‚Üí Code Deploy ‚Üí Dependencies ‚Üí
  # Environment ‚Üí Service Deploy ‚Üí Migration ‚Üí Health Check ‚Üí Summary
  # =============================================================================

  production-shutdown-approval:
    name: "üõë Confirm Production Deployment"
    runs-on: ubuntu-latest
    environment:
      name: production-shutdown
    needs: [build-validation]
    if: github.ref == 'refs/heads/main' && needs.build-validation.outputs.build-passed == 'true'
    steps:
      - name: "üìã Await manual approval"
        run: |
          echo "‚úÖ Manual approval received for production deployment."

  production-deployment:
    name: "üöÄ Production Deployment"
    runs-on: self-hosted
    environment: production
    needs: [build-validation, production-shutdown-approval]
    if: |
      github.ref == 'refs/heads/main' &&
      needs.build-validation.outputs.build-passed == 'true' &&
      needs.production-shutdown-approval.result == 'success'
    timeout-minutes: 15
    concurrency:
      group: prod-deployment
      cancel-in-progress: false  # Queue deployments - never cancel mid-deployment
    env:
      DEPLOY_PATH: /home/nut/loyalty-app-production

    steps:
      - name: "üìä Pre-deployment validation (quality gates & deployment directory)"
        id: validate-deploy-dir
        run: |
          echo "üîç Pre-deployment checks..."
          echo "Build Validation: ${{ needs.build-validation.outputs.build-passed }}"
          echo "Backend Image: ${{ needs.build-validation.outputs.backend-image }}"
          echo "Frontend Image: ${{ needs.build-validation.outputs.frontend-image }}"
          echo "Images Ready: ${{ needs.build-validation.outputs.images-ready }}"

          if [ "${{ needs.build-validation.outputs.build-passed }}" != "true" ]; then
            echo "‚ùå Build validation failed - deployment blocked"
            exit 1
          fi
          echo "‚úÖ All quality gates passed"

          echo ""
          echo "üîó Validating deployment directory..."
          DEPLOY_DIR="${DEPLOY_PATH:-/home/nut/loyalty-app-production}"

          # Directory exists (bind mount working)
          if [ ! -d "$DEPLOY_DIR" ]; then
            echo "‚ùå FATAL: Deployment directory not found: $DEPLOY_DIR"
            echo "Verify runner's docker-compose.yml has bind mount configured"
            exit 1
          fi
          echo "‚úÖ Directory exists: $DEPLOY_DIR"

          # It's a git repository
          if [ ! -d "$DEPLOY_DIR/.git" ]; then
            echo "‚ùå FATAL: Not a git repository: $DEPLOY_DIR"
            exit 1
          fi
          echo "‚úÖ Valid git repository"

          cd "$DEPLOY_DIR"
          git config --global --add safe.directory "$DEPLOY_DIR" 2>/dev/null || true

          # Git commands work
          if ! git rev-parse HEAD >/dev/null 2>&1; then
            echo "‚ùå FATAL: Git commands failing in $DEPLOY_DIR"
            exit 1
          fi
          CURRENT_COMMIT=$(git rev-parse --short HEAD)
          echo "‚úÖ Git working (current commit: $CURRENT_COMMIT)"

          # Remote is configured
          REMOTE_URL=$(git remote get-url origin 2>/dev/null || echo "")
          if [ -z "$REMOTE_URL" ]; then
            echo "‚ùå FATAL: No 'origin' remote configured"
            exit 1
          fi
          echo "‚úÖ Remote configured: origin"

          # Can reach the target commit
          git remote set-url origin https://x-access-token:${{ secrets.GITHUB_TOKEN }}@github.com/${{ github.repository }}.git
          if ! git fetch --depth 1 origin ${{ github.sha }} 2>/dev/null; then
            echo "‚ö†Ô∏è WARNING: Could not fetch commit - will retry during deployment"
          else
            echo "‚úÖ Target commit is reachable"
          fi

          echo ""
          echo "üìã Ready for deployment: $DEPLOY_DIR ($CURRENT_COMMIT ‚Üí ${{ github.sha }})"

      - name: "üíæ Smart database backup (pre-shutdown)"
        id: backup
        run: |
          echo "üíæ Creating smart database backup..."
          
          DEPLOY_DIR="${DEPLOY_PATH:-/home/nut/loyalty-app-production}"
          
          # Only backup if deployment directory exists
          if [ ! -d "$DEPLOY_DIR" ]; then
            echo "‚ö†Ô∏è First deployment - skipping backup"
            echo "status=skipped" >> $GITHUB_OUTPUT
            exit 0
          fi
          
          cd "$DEPLOY_DIR"
          mkdir -p backups
          
          # Quick backup with timeout
          timestamp=$(date +%Y%m%d_%H%M%S)
          backup_file="backups/pre_deploy_${timestamp}.sql"
          
          if timeout 60s docker exec loyalty_postgres_production pg_dump -U loyalty -d loyalty_db > "$backup_file" 2>/dev/null; then
            if [ -s "$backup_file" ]; then
              echo "‚úÖ Backup created: $backup_file ($(du -h "$backup_file" | cut -f1))"
              echo "status=success" >> $GITHUB_OUTPUT
            else
              echo "‚ö†Ô∏è Backup failed - empty file"
              rm -f "$backup_file"
              echo "status=failed" >> $GITHUB_OUTPUT
            fi
          else
            echo "‚ö†Ô∏è Backup timed out or failed"
            rm -f "$backup_file" 2>/dev/null || true
            echo "status=failed" >> $GITHUB_OUTPUT
          fi
      
      - name: "üì• Optimized code deployment"
        run: |
          echo "üì• Deploying code..."

          DEPLOY_DIR="${DEPLOY_PATH:-/home/nut/loyalty-app-production}"
          cd "$DEPLOY_DIR"

          # Show current state
          BEFORE_COMMIT=$(git rev-parse --short HEAD)
          echo "üìç Current commit: $BEFORE_COMMIT"
          echo "üéØ Target commit:  ${{ github.sha }}"

          # Clean any local changes
          echo "üßπ Cleaning local changes..."
          git clean -fd 2>/dev/null || true
          git reset --hard HEAD 2>/dev/null || true

          # Fetch and checkout the specific commit (remote already configured in validation step)
          echo "üì• Fetching and checking out target commit..."
          git fetch --depth 1 origin ${{ github.sha }}
          git checkout ${{ github.sha }}

          # Verify checkout succeeded (use full SHA for robust verification)
          AFTER_COMMIT=$(git rev-parse HEAD)
          TARGET_SHA="${{ github.sha }}"

          if [ "$AFTER_COMMIT" != "$TARGET_SHA" ]; then
            echo "‚ùå ERROR: Checkout verification failed!"
            echo "   Expected: $TARGET_SHA"
            echo "   Got:      $AFTER_COMMIT"
            exit 1
          fi

          echo ""
          echo "‚úÖ Code deployment completed"
          echo "   Before: $BEFORE_COMMIT"
          echo "   Deployed SHA: $AFTER_COMMIT"

      - name: "‚ö° Setup Node.js"
        uses: actions/setup-node@395ad3262231945c25e8478fd5baf05154b1d79f # v6
        with:
          node-version: ${{ env.NODE_VERSION }}

      - name: "‚ö° Lightning-fast dependency setup"
        run: |
          # Verify Node.js version
          echo "üîç Node.js: $(node --version) | npm: $(npm --version)"
          NODE_MAJOR=$(node --version | cut -d'.' -f1 | tr -d 'v')
          if [ "$NODE_MAJOR" -lt "${{ env.NODE_VERSION }}" ]; then
            echo "‚ùå Node.js version mismatch! Expected ${{ env.NODE_VERSION }}.x, got $(node --version)"
            exit 1
          fi

          echo "‚ö° Setting up dependencies with maximum speed..."

          DEPLOY_DIR="${DEPLOY_PATH:-/home/nut/loyalty-app-production}"
          cd "$DEPLOY_DIR"

          # Configure npm for maximum performance
          # Use cache inside deployment directory (bind-mounted from host)
          export NPM_CONFIG_CACHE="$DEPLOY_DIR/.npm-cache"
          export NPM_CONFIG_PREFER_OFFLINE=true
          export NPM_CONFIG_AUDIT=false
          export NPM_CONFIG_FUND=false
          mkdir -p "$NPM_CONFIG_CACHE"
          
          # Parallel dependency installation with smart caching
          install_deps() {
            local service=$1
            local dir=$2
            echo "Installing $service dependencies..."
            cd "$DEPLOY_DIR/$dir"
            
            # Use npm ci for reproducible installs with integrity verification
            # Strictly follows package-lock.json and verifies integrity hashes
            npm ci --prefer-offline --no-audit --ignore-scripts || {
              echo "‚ùå npm ci failed for $service"
              echo "   Ensure package-lock.json is committed and in sync with package.json"
              echo "   Regenerate lock file locally and commit the update"
              exit 1
            }
            echo "‚úÖ $service dependencies installed (integrity verified)"
          }
          
          # Install in parallel
          install_deps "backend" "backend" &
          install_deps "frontend" "frontend" &
          wait
          
          echo "‚úÖ Dependencies installed in parallel"
      
      - name: "üîß Validate secrets & create .env file for Docker Compose"
        run: |
          echo "üîß Configuring production environment..."

          # Validate critical secrets
          missing_secrets=()
          [ -z "${{ secrets.JWT_SECRET }}" ] && missing_secrets+=("JWT_SECRET")
          [ -z "${{ secrets.DATABASE_URL }}" ] && missing_secrets+=("DATABASE_URL")

          if [ ${#missing_secrets[@]} -ne 0 ]; then
            echo "‚ùå Missing secrets: ${missing_secrets[*]}"
            exit 1
          fi
          echo "‚úÖ Critical secrets validated"

          echo ""
          echo "üìù Creating .env file..."
          DEPLOY_DIR="${DEPLOY_PATH:-/home/nut/loyalty-app-production}"
          cd "$DEPLOY_DIR"

          cat > .env << EOF
          NODE_ENV=production
          LOG_LEVEL=info
          CORS_ORIGINS=${{ vars.CORS_ORIGINS }}

          JWT_SECRET=${{ secrets.JWT_SECRET }}
          JWT_REFRESH_SECRET=${{ secrets.JWT_REFRESH_SECRET }}
          SESSION_SECRET=${{ secrets.SESSION_SECRET }}
          DATABASE_URL=${{ secrets.DATABASE_URL }}
          REDIS_URL=${{ vars.REDIS_URL || 'redis://redis:6379' }}
          FRONTEND_URL=${{ vars.FRONTEND_URL }}
          BACKEND_URL=${{ vars.BACKEND_URL }}
          VITE_API_URL=${{ vars.VITE_API_URL }}
          VITE_TRANSLATION_ENABLED=false
          TRANSLATION_FEATURE_ENABLED=false

          GOOGLE_CLIENT_ID=${{ secrets.GOOGLE_CLIENT_ID }}
          GOOGLE_CLIENT_SECRET=${{ secrets.GOOGLE_CLIENT_SECRET }}
          GOOGLE_CALLBACK_URL=${{ vars.GOOGLE_CALLBACK_URL }}
          LINE_CHANNEL_ID=${{ secrets.LINE_CHANNEL_ID }}
          LINE_CHANNEL_SECRET=${{ secrets.LINE_CHANNEL_SECRET }}
          LINE_CALLBACK_URL=${{ vars.LINE_CALLBACK_URL }}

          SMTP_HOST=${{ vars.SMTP_HOST }}
          SMTP_PORT=${{ vars.SMTP_PORT }}
          SMTP_USER=${{ secrets.SMTP_USER }}
          SMTP_PASS=${{ secrets.SMTP_PASS }}
          SMTP_FROM=${{ secrets.SMTP_FROM }}

          IMAP_HOST=${{ vars.IMAP_HOST }}
          IMAP_PORT=${{ vars.IMAP_PORT }}
          IMAP_USER=${{ secrets.SMTP_USER }}
          IMAP_PASS=${{ secrets.SMTP_PASS }}

          SLIPOK_API_KEY=${{ secrets.SLIPOK_API_KEY }}
          SLIPOK_BRANCH_ID=${{ secrets.SLIPOK_BRANCH_ID }}

          LOYALTY_USERNAME=${{ secrets.LOYALTY_USERNAME }}
          LOYALTY_PASSWORD=${{ secrets.LOYALTY_PASSWORD }}
          EOF

          echo "‚úÖ .env file created ($(wc -l < .env) lines)"

          # Validate .env file (without exposing secrets)
          echo "üîç Validation: NODE_ENV=$(grep '^NODE_ENV=' .env | cut -d'=' -f2)"
          empty_vars=$(grep '=$' .env | cut -d'=' -f1 | head -5 || true)
          if [ -n "$empty_vars" ]; then
            echo "‚ö†Ô∏è Empty environment variables detected: $empty_vars"
            echo "   This may cause issues - please check GitHub Secrets/Variables"
          else
            echo "‚úÖ All environment variables have values"
          fi
      
      - name: "üõ°Ô∏è Stop conflicting dev containers & verify production ports available"
        run: |
          echo "üõ°Ô∏è Checking for dev containers that might block production ports..."

          # Stop dev containers that could conflict
          DEV_CONTAINERS=("loyalty_postgres_dev" "loyalty_redis_dev" "loyalty_nginx_dev" "loyalty_backend_dev" "loyalty_frontend_dev")
          STOPPED_CONTAINERS=()
          for container in "${DEV_CONTAINERS[@]}"; do
            if docker ps -a --format '{{.Names}}' | grep -q "^${container}$"; then
              echo "‚ö†Ô∏è Stopping dev container: $container"
              docker stop "$container" 2>/dev/null || true
              docker rm "$container" 2>/dev/null || true
              STOPPED_CONTAINERS+=("$container")
            fi
          done
          [ ${#STOPPED_CONTAINERS[@]} -gt 0 ] && echo "üßπ Removed: ${STOPPED_CONTAINERS[*]}" && sleep 5

          echo ""
          echo "üîç Checking production ports (5434, 6379, 4001)..."
          DEPLOY_DIR="${DEPLOY_PATH:-/home/nut/loyalty-app-production}"
          cd "$DEPLOY_DIR"

          REQUIRED_PORTS=(5434 6379 4001)
          PORTS_IN_USE=()
          for port in "${REQUIRED_PORTS[@]}"; do
            if lsof -i ":$port" -sTCP:LISTEN -t >/dev/null 2>&1; then
              echo "‚ö†Ô∏è Port $port in use"
              PORTS_IN_USE+=($port)
            else
              echo "‚úÖ Port $port available"
            fi
          done

          if [ ${#PORTS_IN_USE[@]} -gt 0 ]; then
            echo "üõë Attempting graceful shutdown..."
            docker compose -f docker-compose.yml -f docker-compose.prod.yml down --timeout 30 || true
            sleep 5

            # Re-check ports
            STILL_IN_USE=()
            for port in "${PORTS_IN_USE[@]}"; do
              lsof -i ":$port" -sTCP:LISTEN -t >/dev/null 2>&1 && STILL_IN_USE+=($port)
            done

            if [ ${#STILL_IN_USE[@]} -gt 0 ]; then
              echo "‚ùå FATAL: Ports still in use: ${STILL_IN_USE[*]}"
              exit 1
            fi
            echo "‚úÖ Ports freed after shutdown"
          fi
          echo "‚úÖ All production ports available"

      - name: "üîí Validate production configuration"
        run: |
          echo "üîí Validating production configuration..."

          DEPLOY_DIR="${DEPLOY_PATH:-/home/nut/loyalty-app-production}"
          cd "$DEPLOY_DIR"

          HAS_ERROR=0

          # Check 1: Verify no dev commands in production config
          echo "üìã Checking for dev commands in production config..."

          # Get merged config as YAML
          MERGED_CONFIG=$(docker compose -f docker-compose.yml -f docker-compose.prod.yml config 2>/dev/null)

          # Extract backend command using yq-style parsing (grep between backend: and next service)
          # Look for command: in the backend service section
          BACKEND_SECTION=$(echo "$MERGED_CONFIG" | sed -n '/^  backend:/,/^  [a-z]/p' | head -n -1)
          BACKEND_CMD=$(echo "$BACKEND_SECTION" | grep "command:" | head -1 || echo "")

          echo "   Backend command config: ${BACKEND_CMD:-'(none - using Dockerfile CMD)'}"

          if echo "$BACKEND_CMD" | grep -qE "(npm run dev|npx tsx|nodemon|ts-node)"; then
            echo "‚ùå FATAL: Development command found in backend service!"
            echo "   Found: $BACKEND_CMD"
            echo "   Production must use Dockerfile CMD: node dist/index.js"
            HAS_ERROR=1
          else
            echo "‚úÖ Backend command OK (using Dockerfile CMD or explicit production command)"
          fi

          # Also check base docker-compose.yml directly for dev commands that might leak
          echo "üìã Verifying base docker-compose.yml doesn't have dev commands..."
          BASE_BACKEND_CMD=$(grep -A30 "^  backend:" docker-compose.yml | grep "command:" | head -1 || echo "")
          if echo "$BASE_BACKEND_CMD" | grep -qE "(npm run dev|npx tsx|nodemon|ts-node)"; then
            echo "‚ùå FATAL: Development command in base docker-compose.yml!"
            echo "   Found: $BASE_BACKEND_CMD"
            echo "   Dev commands must be in docker-compose.dev.yml only"
            HAS_ERROR=1
          else
            echo "‚úÖ Base docker-compose.yml OK (no dev commands)"
          fi

          # Check 2: Verify backend uses runner target (production stage)
          BACKEND_TARGET=$(echo "$MERGED_CONFIG" | grep -A20 "backend:" | grep -A10 "build:" | grep "target:" | head -1 || echo "")
          if echo "$BACKEND_TARGET" | grep -q "development"; then
            echo "‚ùå FATAL: Backend using development Docker target!"
            echo "   Found: $BACKEND_TARGET"
            echo "   Production must use: target: runner"
            HAS_ERROR=1
          else
            echo "‚úÖ Backend Docker target OK"
          fi

          # Check 3: Verify NODE_ENV is production
          NODE_ENV_VALUE=$(echo "$MERGED_CONFIG" | grep -A100 "backend:" | grep "NODE_ENV:" | head -1 || echo "")
          if echo "$NODE_ENV_VALUE" | grep -qE "(development|dev)"; then
            echo "‚ùå FATAL: NODE_ENV not set to production!"
            echo "   Found: $NODE_ENV_VALUE"
            HAS_ERROR=1
          else
            echo "‚úÖ NODE_ENV OK"
          fi

          if [ $HAS_ERROR -eq 1 ]; then
            echo ""
            echo "üõë Production deployment blocked due to configuration errors."
            echo "   Please fix docker-compose.prod.yml before deploying."
            exit 1
          fi

          echo "‚úÖ Production configuration validated"

      - name: "üöÄ Optimized service deployment"
        run: |
          echo "üöÄ Deploying services with zero-downtime strategy..."

          DEPLOY_DIR="${DEPLOY_PATH:-/home/nut/loyalty-app-production}"
          cd "$DEPLOY_DIR"

          # Enable BuildKit for faster builds
          export DOCKER_BUILDKIT=1
          export COMPOSE_DOCKER_CLI_BUILD=1
          
          # Build and start services
          # Dockerfiles are optimized for caching:
          # - Dependencies cached until package*.json changes
          # - Config files cached until they change
          # - Source code copied LAST (only build layer rebuilds on code changes)
          echo "üèóÔ∏è Building and starting services..."
          docker compose -f docker-compose.yml -f docker-compose.prod.yml up -d --build
          
          echo "‚úÖ Services deployed"
          
          # Give services time to initialize before health checks
          echo "‚è≥ Allowing services to initialize (30 seconds)..."
          sleep 30
          
          # Quick startup verification
          echo "üîç Quick startup verification:"
          docker compose ps
          echo "üìù Backend startup logs (last 10 lines):"
          docker compose logs --tail=10 backend 2>/dev/null || echo "No backend logs yet"
      
      - name: "üóÉÔ∏è Database migration (container context)"
        run: |
          echo "üóÉÔ∏è Waiting for backend migrations to complete..."

          DEPLOY_DIR="${DEPLOY_PATH:-/home/nut/loyalty-app-production}"
          cd "$DEPLOY_DIR"

          # Pre-migration container status
          echo "üì¶ Container status:"
          docker compose ps

          # Wait for backend to be healthy (entrypoint.sh runs migrations)
          # Backend health check means migrations have completed successfully
          echo "‚è≥ Waiting for backend health check..."
          for i in {1..60}; do
            if docker compose exec -T backend \
               curl -sf http://localhost:4000/api/health > /dev/null 2>&1; then
              echo "‚úÖ Backend is healthy (migrations complete)"
              break
            fi

            if [ $i -eq 60 ]; then
              echo "‚ùå Backend failed to become healthy after 2 minutes"
              echo "üìÑ Backend logs:"
              docker compose logs --tail=50 backend
              exit 1
            fi

            echo "Waiting for backend... ($i/60)"
            sleep 2
          done

          # Verify migration status (read-only, no execution)
          echo "üîç Verifying migration status..."
          docker compose exec -T backend npx prisma migrate status

          echo "‚úÖ Database migration phase completed"
      
      - name: "üîêüóÑÔ∏è Post-deployment OAuth & database validation"
        run: |
          echo "üîê Validating OAuth and database in production..."
          DEPLOY_DIR="${DEPLOY_PATH:-/home/nut/loyalty-app-production}"
          cd "$DEPLOY_DIR"

          # Wait for application to be ready
          sleep 10

          # OAuth validation
          echo "üîç Running OAuth validation..."
          if docker compose exec -T backend test -f "/app/scripts/validate-oauth-health.sh"; then
            if docker compose exec -T backend bash -c "cd /app && ./scripts/validate-oauth-health.sh"; then
              echo "‚úÖ OAuth validation passed"
            else
              echo "‚ö†Ô∏è OAuth validation failed - check configuration"
              docker compose logs --tail=10 backend
            fi
          else
            echo "‚ö†Ô∏è OAuth script not found - skipping"
          fi

          # Database migration status
          echo ""
          echo "üóÑÔ∏è Checking database migration status..."
          docker compose exec -T backend npm run db:migrate:status && echo "‚úÖ Migration status OK" || echo "‚ö†Ô∏è Cannot verify migration status"

          # Verify critical tables exist
          echo ""
          echo "üìã Verifying critical database tables..."
          TABLES_CHECK=$(docker compose exec -T postgres psql -U loyalty -d loyalty_db -t -c "
            SELECT string_agg(tablename, ',')
            FROM pg_tables
            WHERE schemaname = 'public'
            AND tablename IN ('users', 'coupons', 'user_coupons', 'tiers', 'user_loyalty', 'user_audit_log', 'surveys');
          " 2>/dev/null | tr -d ' \n')

          REQUIRED_TABLES="users,coupons,user_coupons,tiers,user_loyalty,user_audit_log,surveys"
          MISSING_TABLES=""
          for table in $(echo "$REQUIRED_TABLES" | tr ',' ' '); do
            if ! echo "$TABLES_CHECK" | grep -q "$table"; then
              MISSING_TABLES="$MISSING_TABLES $table"
            fi
          done

          if [ -n "$MISSING_TABLES" ]; then
            echo "‚ùå Missing tables:$MISSING_TABLES"
            exit 1
          else
            echo "‚úÖ All critical tables exist"
          fi

          # Verify critical stored procedures exist
          echo ""
          echo "üìã Verifying critical stored procedures..."
          FUNCTIONS_CHECK=$(docker compose exec -T postgres psql -U loyalty -d loyalty_db -t -c "
            SELECT string_agg(proname, ',')
            FROM pg_proc p
            JOIN pg_namespace n ON p.pronamespace = n.oid
            WHERE n.nspname = 'public'
            AND proname IN (
              'assign_coupon_to_user',
              'redeem_coupon',
              'award_points',
              'recalculate_user_tier_by_nights'
            );
          " 2>/dev/null | tr -d ' \n')

          REQUIRED_FUNCTIONS="assign_coupon_to_user,redeem_coupon,award_points,recalculate_user_tier_by_nights"
          MISSING_FUNCTIONS=""
          for func in $(echo "$REQUIRED_FUNCTIONS" | tr ',' ' '); do
            if ! echo "$FUNCTIONS_CHECK" | grep -q "$func"; then
              MISSING_FUNCTIONS="$MISSING_FUNCTIONS $func"
            fi
          done

          if [ -n "$MISSING_FUNCTIONS" ]; then
            echo "‚ùå Missing stored procedures:$MISSING_FUNCTIONS"
            echo "‚ö†Ô∏è Database drift detected - stored procedures missing"
            exit 1
          else
            echo "‚úÖ All critical stored procedures exist"
          fi

          echo "‚úÖ Database schema verification completed"

          # Rollback safety check
          if docker compose exec -T backend test -f "/app/scripts/migration-rollback-safety.sh"; then
            echo "üîç Running rollback safety check..."
            docker compose exec -T backend bash -c "cd /app && ./scripts/migration-rollback-safety.sh check" && echo "‚úÖ Rollback safety OK" || echo "‚ö†Ô∏è Rollback safety check failed"
          fi

      - name: "üè• Health checks & validation (service readiness)"
        run: |
          echo "üè• Running comprehensive health checks with enhanced logging..."
          
          DEPLOY_DIR="${DEPLOY_PATH:-/home/nut/loyalty-app-production}"
          cd "$DEPLOY_DIR"
          
          # Enhanced logging function with container inspection
          enhanced_health_check() {
            local service=$1
            local url=$2
            local max_attempts=15
            local attempt=0
            
            echo "üîç Starting health check for $service at $url"
            
            # First, check container status
            echo "üì¶ Checking container status..."
            docker compose ps
            
            # Show container logs for startup diagnostics
            echo "üìú Recent startup logs from containers:"
            echo "=== Backend Logs (last 50 lines) ==="
            docker compose logs --tail=50 backend 2>/dev/null || echo "No backend logs available"
            
            echo "\n=== Frontend Logs (last 20 lines) ==="
            docker compose logs --tail=20 frontend 2>/dev/null || echo "No frontend logs available"
            
            echo "\n=== Database Logs (last 10 lines) ==="
            docker compose logs --tail=10 postgres 2>/dev/null || echo "No database logs available"
            
            # Check if containers are actually running
            if ! docker compose ps | grep -q "Up"; then
              echo "‚ùå Critical: No containers are running!"
              echo "üî¥ Container status details:"
              docker compose ps -a
              return 1
            fi
            
            # Enhanced health checking with detailed diagnostics
            while [ $attempt -lt $max_attempts ]; do
              echo "üîÑ Health Check Attempt $((attempt + 1))/$max_attempts for $service"
              
              # Test with verbose curl output for diagnostics
              if curl -f -s --max-time 3 "$url" > /dev/null 2>&1; then
                echo "‚úÖ $service is healthy and responding"
                
                # Additional validation - get response details
                response=$(curl -s --max-time 3 "$url" 2>/dev/null || echo "No response body")
                echo "üìÑ Response preview: ${response:0:200}..."
                return 0
              else
                # Detailed failure diagnostics
                http_code=$(curl -s -o /dev/null -w "%{http_code}" --max-time 3 "$url" 2>/dev/null || echo "000")
                echo "‚ö†Ô∏è $service not ready (HTTP: $http_code)"
                
                # Every 3rd attempt, show detailed diagnostics
                if [ $((attempt % 3)) -eq 0 ] && [ $attempt -gt 0 ]; then
                  echo "üîç Diagnostic info (attempt $((attempt + 1))):"
                  echo "  - Port check:" $(nc -z localhost 4001 && echo "Port 4001 open" || echo "Port 4001 closed")
                  echo "  - Backend container:" $(docker compose exec -T backend echo "responsive" 2>/dev/null || echo "not responding")
                  echo "  - Recent backend errors:"
                  docker compose logs --tail=5 backend 2>/dev/null | grep -i "error\|fail\|exception" | tail -3 || echo "    No recent errors found"
                fi
              fi
              
              attempt=$((attempt + 1))
              [ $attempt -lt $max_attempts ] && sleep 2
            done
            
            echo "‚ùå $service health check failed after $max_attempts attempts"
            
            # Final diagnostic dump on failure
            echo "üî¥ FAILURE DIAGNOSTICS:"
            echo "=== Container Status ==="
            docker compose ps -a
            
            echo "\n=== Network Status ==="
            docker compose exec -T backend cat /etc/hosts 2>/dev/null | head -5 || echo "Cannot access container network info"
            
            echo "\n=== Application Ports ==="
            docker compose exec -T backend netstat -tlnp 2>/dev/null | grep -E ":3000|:4001" || echo "Cannot check application ports"
            
            echo "\n=== Final Backend Logs ==="
            docker compose logs --tail=30 backend
            
            echo "\n=== System Resources ==="
            echo "Memory:" $(free -h | head -2 | tail -1)
            echo "Disk:" $(df -h / | tail -1)
            
            return 1
          }
          
          # Run enhanced health checks
          enhanced_health_check "Application" "http://localhost:4001/api/health"
          
          # If backend is healthy, check frontend
          echo "\nüåê Checking frontend..."
          if curl -f -s --max-time 3 "http://localhost:4001/" > /dev/null 2>&1; then
            echo "‚úÖ Frontend is responding"
          else
            echo "‚ö†Ô∏è Frontend not responding (non-critical for deployment)"
            echo "üìÑ Frontend logs:"
            docker compose logs --tail=10 frontend
          fi
          
          echo "‚úÖ Health checks completed successfully"

      - name: "üìß Verify email service configuration"
        run: |
          echo "üîç Checking email service configuration..."

          # Query backend container directly to bypass nginx HTTPS redirect
          HEALTH_RESPONSE=$(docker compose exec -T backend curl -sf --max-time 10 http://localhost:4000/api/health 2>/dev/null || echo '{}')
          EMAIL_STATUS=$(echo "$HEALTH_RESPONSE" | jq -r '.services.email // "unknown"')

          case "$EMAIL_STATUS" in
            "configured")
              echo "‚úÖ Email service: Configured"
              echo "   SMTP credentials are set"
              ;;
            "not_configured")
              echo "‚ö†Ô∏è Email service: Not configured"
              echo "   Missing SMTP_HOST, SMTP_USER, SMTP_PASS, or SMTP_FROM"
              ;;
            *)
              echo "‚ùì Email service: $EMAIL_STATUS"
              echo "   (Could not determine status - this is non-blocking)"
              ;;
          esac

  # =============================================================================
  # PHASE 4: POST-DEPLOYMENT MONITORING & CLEANUP
  # =============================================================================
  
  post-deployment:
    name: "üìä Post-Deployment"
    runs-on: self-hosted
    needs: production-deployment
    if: always() && (needs.production-deployment.result == 'success' || needs.production-deployment.result == 'failure')
    timeout-minutes: 3
    continue-on-error: true  # Don't block pipeline completion on post-deployment issues
    
    steps:
      - name: "üîç Pre-deployment health check"
        timeout-minutes: 1
        run: |
          echo "üîç Checking runner status..."
          echo "Runner: $(hostname)"
          echo "Load: $(uptime)"
          echo "Memory: $(free -h 2>/dev/null || vm_stat | head -10)"
          echo "Disk: $(df -h / | tail -1)"
          echo "‚úÖ Runner health check passed"

      - name: "‚ö†Ô∏è Automatic Rollback on Failure"
        if: failure()
        timeout-minutes: 3
        run: |
          echo "‚ö†Ô∏è Deployment failed - initiating automatic rollback..."

          DEPLOY_DIR="${DEPLOY_PATH:-/home/nut/loyalty-app-production}"
          cd "$DEPLOY_DIR"

          # Find previous working images (excluding current SHA)
          CURRENT_SHA="${{ github.sha }}"
          echo "üîç Looking for previous working images (excluding $CURRENT_SHA)..."

          PREV_BACKEND=$(docker images loyalty-app-backend --format "{{.Tag}}" | grep -v "latest" | grep -v "$CURRENT_SHA" | head -1)
          PREV_FRONTEND=$(docker images loyalty-app-frontend --format "{{.Tag}}" | grep -v "latest" | grep -v "$CURRENT_SHA" | head -1)

          if [ -n "$PREV_BACKEND" ] && [ -n "$PREV_FRONTEND" ]; then
            echo "üì¶ Rolling back to previous images:"
            echo "  Backend: loyalty-app-backend:$PREV_BACKEND"
            echo "  Frontend: loyalty-app-frontend:$PREV_FRONTEND"

            # Export previous image tags
            export BACKEND_IMAGE="loyalty-app-backend:$PREV_BACKEND"
            export FRONTEND_IMAGE="loyalty-app-frontend:$PREV_FRONTEND"

            # Perform rollback with same hot-swap strategy
            echo "üîÑ Rolling back backend..."
            docker compose -f docker-compose.yml -f docker-compose.prod.yml \
              up -d --no-build --no-deps backend

            sleep 10

            echo "üîÑ Rolling back frontend..."
            docker compose -f docker-compose.yml -f docker-compose.prod.yml \
              up -d --no-build --no-deps frontend

            sleep 10

            # Verify rollback
            echo "üè• Verifying rollback health..."
            if timeout 30s bash -c 'until curl -f -s http://localhost:4001/api/health >/dev/null 2>&1; do sleep 2; done'; then
              echo "‚úÖ Rollback successful - service health check passed"
              echo "üìä Rollback summary:"
              echo "  Rolled back from: $CURRENT_SHA"
              echo "  Rolled back to: $PREV_BACKEND"
              docker compose ps
            else
              echo "‚ùå Rollback health check failed"
              echo "üìÑ Backend logs after rollback:"
              docker compose logs --tail=20 backend
            fi
          else
            echo "‚ö†Ô∏è No previous images found for rollback"
            echo "Available backend images:"
            docker images loyalty-app-backend
            echo "Available frontend images:"
            docker images loyalty-app-frontend
          fi

          echo "üî¥ Deployment failed and rollback attempted"
          echo "Please review the logs above for details"

      - name: "üìä Deployment summary (reporting only)"
        timeout-minutes: 1
        run: |
          echo "==============================================="
          echo "üìä DEPLOYMENT SUMMARY"
          echo "==============================================="
          echo "Repository: ${{ github.repository }}"
          echo "Branch: ${{ github.ref_name }}"
          echo "Commit: ${{ github.sha }}"
          echo "Actor: ${{ github.actor }}"
          echo "Timestamp: $(date -Iseconds)"
          echo ""
          echo "üéØ Job Results:"
          echo "Validate & Test: ${{ needs.validate-and-test.result }}"
          echo "E2E Tests: ${{ needs.e2e-tests.result || 'skipped' }}"
          echo "Build Validation: ${{ needs.build-validation.result }}"
          echo "Production Deployment: ${{ needs.production-deployment.result }}"
          echo ""
          echo "üìà Metrics:"
          echo "Test Coverage: ${{ needs.validate-and-test.outputs.coverage-percent }}%"
          echo ""
          echo "üåê Service Endpoints:"
          echo "Application: https://loyalty.saichon.com"
          echo "Health Check: https://loyalty.saichon.com/api/health"
          echo "==============================================="
      
      - name: "üåê Service health validation"
        timeout-minutes: 1
        run: |
          echo "üåê Testing deployed services..."
          
          # Test health endpoint with timeout and retry
          for i in {1..3}; do
            if curl -s --max-time 10 "https://loyalty.saichon.com/api/health" | grep -q "ok\|healthy\|success" 2>/dev/null; then
              echo "‚úÖ Service health check passed (attempt $i)"
              break
            else
              echo "‚ö†Ô∏è Health check failed (attempt $i/3)"
              [ $i -eq 3 ] && echo "üö® All health checks failed - service may be unhealthy"
              sleep 5
            fi
          done
      
      - name: "üßπ Smart cleanup (non-blocking)"
        timeout-minutes: 1
        continue-on-error: true
        run: |
          echo "üßπ Running smart cleanup with strict timeouts..."
          
          # Set strict timeout for all operations
          set +e  # Don't exit on command failures in cleanup
          
          # Check disk usage with timeout
          DISK_USAGE=$(timeout 10s df / | tail -1 | awk '{print $5}' | sed 's/%//' 2>/dev/null || echo "unknown")
          echo "üíæ Disk usage: ${DISK_USAGE}%"
          
          # Clean up old TEST containers only (NEVER prune all - protects dev containers)
          echo "üê≥ Cleaning old test containers..."
          # Only remove E2E test containers, never use 'docker container prune' which could delete dev containers
          for container in loyalty_postgres_e2e loyalty_redis_e2e loyalty_backend_e2e loyalty_frontend_e2e \
                          loyalty_postgres_unit loyalty_redis_unit loyalty_postgres_integration loyalty_redis_integration; do
            docker rm -f "$container" 2>/dev/null || true
          done
          echo "‚úÖ Test containers cleaned (dev/prod containers preserved)"
          
          # Clean up old images with timeout (keep last 3 versions)
          echo "üñºÔ∏è Cleaning old images..."
          timeout 20s docker image prune -f --filter "until=72h" 2>/dev/null || echo "‚ö†Ô∏è Image cleanup timed out"
          
          # Clean up build cache with timeout
          echo "üßπ Cleaning build cache..."
          timeout 10s docker builder prune -f --filter "until=24h" 2>/dev/null || echo "‚ö†Ô∏è Build cache cleanup timed out"
          
          echo "‚úÖ Cleanup completed (may have warnings, non-blocking)"

      - name: "üìã Post-deployment summary"
        timeout-minutes: 1
        continue-on-error: true
        env:
          DEPLOY_RESULT: ${{ needs.production-deployment.result }}
        run: |
          echo "==============================================="
          echo "üìã DEPLOYMENT RESULT"
          echo "==============================================="

          if [ "$DEPLOY_RESULT" = "success" ]; then
            HEALTH_CODE=$(curl -s -o /dev/null -w '%{http_code}' https://loyalty.saichon.com/api/health 2>/dev/null || echo 'timeout')
            echo "üéâ Deployment Status: ‚úÖ SUCCESS"
            echo "‚îú‚îÄ‚îÄ üåê Frontend: https://loyalty.saichon.com"
            echo "‚îú‚îÄ‚îÄ üîó Backend: https://loyalty.saichon.com/api"
            echo "‚îú‚îÄ‚îÄ üìä Health check: $HEALTH_CODE"
            echo "‚îî‚îÄ‚îÄ üïí Completed at: $(date)"
          else
            echo "‚ùå Deployment Status: FAILED"
            echo "‚îú‚îÄ‚îÄ Result: $DEPLOY_RESULT"
            echo "‚îú‚îÄ‚îÄ Commit: ${{ github.sha }}"
            echo "‚îú‚îÄ‚îÄ Branch: ${{ github.ref_name }}"
            echo "‚îî‚îÄ‚îÄ üïí Failed at: $(date)"
            echo ""
            echo "üîç Check the 'Production Deployment' job logs for details"
          fi

          echo "==============================================="
          echo "üéä Post-deployment job completed - pipeline will not get stuck"

      - name: "üßπ Cleanup production env file"
        if: always()
        run: |
          DEPLOY_DIR="${DEPLOY_PATH:-/home/nut/loyalty-app-production}"
          if [ -d "$DEPLOY_DIR" ]; then
            rm -f "$DEPLOY_DIR/.env" || true
            echo "‚úÖ Cleaned up .env file in $DEPLOY_DIR"
          else
            echo "‚ö†Ô∏è Deploy directory $DEPLOY_DIR does not exist - skipping cleanup"
          fi

  # =============================================================================
  # UNIFIED TEST REPORT GENERATION (Merges all test types)
  # =============================================================================

  generate-test-reports:
    name: "üìä Generate Unified Test Reports"
    runs-on: ubuntu-latest
    needs: [validate-and-test, e2e-tests]
    # Only generate reports if at least one test job succeeded (has actual results)
    # Skip if both jobs failed/cancelled/skipped to avoid publishing empty "?" results
    if: |
      github.ref == 'refs/heads/main' &&
      (needs.validate-and-test.result == 'success' || needs.e2e-tests.result == 'success')

    # Prevent multiple concurrent report generations to avoid artifact conflicts
    concurrency:
      group: "test-reports-${{ github.repository }}"
      cancel-in-progress: true

    steps:
      - name: "üì• Checkout code"
        uses: actions/checkout@8e8c483db84b4bee98b60c0593521ed34d9990e8 # v6
        with:
          fetch-depth: 1

      - name: "‚ö° Setup Node.js"
        uses: actions/setup-node@395ad3262231945c25e8478fd5baf05154b1d79f # v6
        with:
          node-version: ${{ env.NODE_VERSION }}

      - name: "üì• Download unit test results"
        uses: actions/download-artifact@37930b1c2abaa49bbe596cd826c3c89aef350131 # v7.0.0
        with:
          name: allure-results-unit-${{ github.run_id }}
          path: allure-results-unit/
        continue-on-error: true

      - name: "üì• Download integration test results"
        uses: actions/download-artifact@37930b1c2abaa49bbe596cd826c3c89aef350131 # v7.0.0
        with:
          name: allure-results-integration-${{ github.run_id }}
          path: allure-results-integration/
        continue-on-error: true

      - name: "üì• Download E2E test results"
        uses: actions/download-artifact@37930b1c2abaa49bbe596cd826c3c89aef350131 # v7.0.0
        with:
          name: allure-results-e2e-${{ github.run_id }}
          path: allure-results-e2e/
        continue-on-error: true

      - name: "üì• Download coverage report"
        uses: actions/download-artifact@37930b1c2abaa49bbe596cd826c3c89aef350131 # v7.0.0
        with:
          name: coverage-report-${{ github.run_id }}
          path: coverage-report/
        continue-on-error: true

      - name: "üîÄ Merge all test results"
        run: |
          # Verify Node.js version
          echo "üîç Node.js: $(node --version) | npm: $(npm --version)"
          NODE_MAJOR=$(node --version | cut -d'.' -f1 | tr -d 'v')
          if [ "$NODE_MAJOR" -lt "${{ env.NODE_VERSION }}" ]; then
            echo "‚ùå Node.js version mismatch! Expected ${{ env.NODE_VERSION }}.x, got $(node --version)"
            exit 1
          fi

          echo "üîÄ Merging test results from all test types..."

          # Create combined results directory
          mkdir -p backend/allure-results-combined

          # Copy unit test results
          if [ -d "allure-results-unit" ] && [ "$(ls -A allure-results-unit 2>/dev/null)" ]; then
            echo "‚úÖ Copying unit test results..."
            cp -r allure-results-unit/* backend/allure-results-combined/ 2>/dev/null || true
            UNIT_COUNT=$(ls -1 allure-results-unit | wc -l)
            echo "   üìä Unit test files: $UNIT_COUNT"
          else
            echo "‚ö†Ô∏è No unit test results found"
          fi

          # Copy integration test results
          if [ -d "allure-results-integration" ] && [ "$(ls -A allure-results-integration 2>/dev/null)" ]; then
            echo "‚úÖ Copying integration test results..."
            cp -r allure-results-integration/* backend/allure-results-combined/ 2>/dev/null || true
            INTEGRATION_COUNT=$(ls -1 allure-results-integration | wc -l)
            echo "   üìä Integration test files: $INTEGRATION_COUNT"
          else
            echo "‚ö†Ô∏è No integration test results found"
          fi

          # Copy E2E test results
          if [ -d "allure-results-e2e" ] && [ "$(ls -A allure-results-e2e 2>/dev/null)" ]; then
            echo "‚úÖ Copying E2E test results..."
            cp -r allure-results-e2e/* backend/allure-results-combined/ 2>/dev/null || true
            E2E_COUNT=$(ls -1 allure-results-e2e | wc -l)
            echo "   üìä E2E test files: $E2E_COUNT"
          else
            echo "‚ö†Ô∏è No E2E test results found"
          fi

          # Count total merged results
          TOTAL_COUNT=$(ls -1 backend/allure-results-combined 2>/dev/null | wc -l)
          echo "üìä Total merged test result files: $TOTAL_COUNT"

          if [ "$TOTAL_COUNT" -eq 0 ]; then
            echo "‚ö†Ô∏è No test results to merge - creating placeholder"
            mkdir -p backend/allure-results-combined
            echo '{"name":"No tests found","status":"broken"}' > backend/allure-results-combined/placeholder.json
          fi

      - name: "‚òï Setup Java for Allure"
        uses: actions/setup-java@f2beeb24e141e01a676f977032f5a29d81c9e27e # v4
        with:
          distribution: 'temurin'
          java-version: '17'

      - name: "üìä Install Allure CLI & generate unified test report"
        run: |
          cd backend

          # Install allure-commandline from package.json (integrity verified via package-lock.json)
          npm ci --prefer-offline --no-audit --ignore-scripts

          echo "üìä Generating unified Allure report from merged results..."

          if [ -d "allure-results-combined" ] && [ "$(ls -A allure-results-combined)" ]; then
            echo "‚úÖ Generating Allure report..."
            npx allure generate allure-results-combined --clean -o allure-report
            echo "‚úÖ Unified Allure report generated successfully"
            echo "üìä Report includes: Unit Tests + Integration Tests + E2E Tests (Playwright)"
          else
            echo "‚ö†Ô∏è No test results found, creating placeholder report"
            mkdir -p allure-report
            cat > allure-report/index.html <<'EOF'
          <!DOCTYPE html>
          <html>
          <head><title>No Test Results</title></head>
          <body><h1>No test results available for this run</h1></body>
          </html>
          EOF
          fi

      - name: "üì¶ Create redirect page & prepare GitHub Pages artifact structure"
        run: |
          echo "üîó Creating latest redirect page..."
          mkdir -p test-reports-latest

          BRANCH_NAME="${{ github.ref_name }}"
          if [ "$BRANCH_NAME" = "main" ]; then
            BADGE_COLOR="#28a745"; BADGE_TEXT="üöÄ PRODUCTION"; ENV_NAME="Production"
          else
            BADGE_COLOR="#17a2b8"; BADGE_TEXT="üß™ DEVELOPMENT"; ENV_NAME="Development"
          fi

          cat > test-reports-latest/index.html <<REDIRECT_EOF
          <!DOCTYPE html>
          <html lang="en">
          <head>
              <meta charset="UTF-8">
              <meta name="viewport" content="width=device-width, initial-scale=1.0">
              <title>[$ENV_NAME] Test Report #${{ github.run_number }}</title>
              <style>
                  body { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif; display: flex; justify-content: center; align-items: center; min-height: 100vh; margin: 0; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; }
                  .container { text-align: center; padding: 2rem; background: rgba(255,255,255,0.1); border-radius: 10px; backdrop-filter: blur(10px); max-width: 500px; }
                  .badge { display: inline-block; padding: 0.5rem 1rem; background: $BADGE_COLOR; border-radius: 20px; font-weight: bold; margin-bottom: 1rem; }
                  .links { display: flex; gap: 1rem; justify-content: center; margin: 1.5rem 0; flex-wrap: wrap; }
                  .link-btn { display: inline-block; padding: 0.75rem 1.5rem; background: rgba(255,255,255,0.2); border-radius: 8px; color: white; text-decoration: none; transition: background 0.2s; }
                  .link-btn:hover { background: rgba(255,255,255,0.3); }
                  .link-btn.primary { background: rgba(255,255,255,0.3); }
                  .meta { font-size: 0.9rem; opacity: 0.8; margin-top: 1rem; }
              </style>
          </head>
          <body>
              <div class="container">
                  <div class="badge">$BADGE_TEXT</div>
                  <h2>Test Reports #${{ github.run_number }}</h2>
                  <div class="links">
                      <a href="../${{ github.run_number }}/" class="link-btn primary">üìä Allure Report</a>
                      <a href="../${{ github.run_number }}/coverage/lcov-report/" class="link-btn">üìà Coverage Report</a>
                  </div>
                  <div class="meta">Branch: $BRANCH_NAME | Commit: ${{ github.sha }}</div>
              </div>
          </body>
          </html>
          REDIRECT_EOF
          echo "‚úÖ Redirect page created for $ENV_NAME"

          echo ""
          echo "üì¶ Preparing GitHub Pages artifact..."
          mkdir -p pages-artifact/test-reports

          if [ -d "backend/allure-report" ]; then
            cp -r backend/allure-report pages-artifact/test-reports/${{ github.run_number }}
            echo "‚úÖ Allure report copied"
          else
            mkdir -p pages-artifact/test-reports/${{ github.run_number }}
            echo "<h1>No test results</h1>" > pages-artifact/test-reports/${{ github.run_number }}/index.html
          fi

          # Include coverage report if available
          if [ -d "coverage-report" ] && [ "$(ls -A coverage-report 2>/dev/null)" ]; then
            mkdir -p pages-artifact/test-reports/${{ github.run_number }}/coverage
            cp -r coverage-report/* pages-artifact/test-reports/${{ github.run_number }}/coverage/
            echo "‚úÖ Coverage report copied"
          else
            echo "‚ö†Ô∏è No coverage report found"
          fi

          mkdir -p pages-artifact/test-reports/latest
          cp -r test-reports-latest/* pages-artifact/test-reports/latest/

          cat > pages-artifact/index.html <<'ROOT_EOF'
          <!DOCTYPE html>
          <html><head><meta http-equiv="refresh" content="0; url=./test-reports/latest/"><title>Test Reports</title></head>
          <body><p>Redirecting to <a href="./test-reports/latest/">latest report</a>...</p></body></html>
          ROOT_EOF

          echo "‚úÖ Artifact prepared ($(du -sh pages-artifact/ | cut -f1))"

      - name: "üì§ Upload GitHub Pages artifact"
        uses: actions/upload-pages-artifact@7b1f4a764d45c48632c6b24a0339c27f5614fb0b # v4
        with:
          path: pages-artifact
          retention-days: 90
          # Note: artifact name is always 'github-pages' for this action

  # =============================================================================
  # GITHUB PAGES DEPLOYMENT (Deploys unified test reports)
  # Uses concurrency to prevent duplicate artifact conflicts
  # =============================================================================

  deploy-github-pages:
    name: "üìÑ Deploy to GitHub Pages"
    runs-on: ubuntu-latest
    needs: [generate-test-reports]
    # Only deploy if report generation succeeded (has valid test results)
    if: github.ref == 'refs/heads/main' && needs.generate-test-reports.result == 'success'

    permissions:
      pages: write
      id-token: write
      contents: read

    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}

    # Strict concurrency - only one pages deployment at a time
    # This prevents the "Multiple artifacts named github-pages" error
    concurrency:
      group: "pages-deploy-${{ github.repository }}"
      cancel-in-progress: true

    steps:
      - name: "‚è≥ Wait for artifact to be ready"
        run: |
          echo "‚è≥ Waiting for artifact processing..."
          sleep 5
          echo "‚úÖ Proceeding with deployment"

      - name: "üöÄ Deploy to GitHub Pages"
        id: deployment
        uses: actions/deploy-pages@d6db90164ac5ed86f2b6aed7e0febac5b3c0c03e # v4
        with:
          timeout: 600000
          error_count: 10
          reporting_interval: 5000
        # Uses default artifact_name: github-pages

      - name: "‚úÖ Deployment complete"
        run: |
          echo "üìÑ GitHub Pages deployed successfully!"
          echo "üîó URL: ${{ steps.deployment.outputs.page_url }}"
          echo "üìä Test Reports: ${{ steps.deployment.outputs.page_url }}test-reports/latest/"

# =============================================================================
# PIPELINE SUMMARY:
#
# üìä PERFORMANCE OPTIMIZATIONS:
# - Parallel job execution with isolated environments (prevents conflicts)
# - Port isolation strategy (Unit: 5438/6383, Integration: 5437/6382, E2E: 5436/6381/4202/3201, Dev: 5435/6380)
# - Container isolation with unique project names and containers
# - Intelligent caching (npm, Docker BuildKit)
# - Conditional jobs (E2E only on main/PR to main)
# - Smart dependency installation
# - Shallow git clones
# - Optimized Docker builds
#
# üîí SECURITY & QUALITY:
# - ESLint security rules
# - npm audit
# - Custom security validation
# - Test integrity validation (prevents test bypassing)
# - TypeScript type checking
# - Unit tests (parallel)
# - Integration tests (parallel)
# - E2E tests (conditional)
# - Database schema tests
# - OAuth health validation (pre & post deployment)
# - Database migration validation & rollback safety
# - OAuth E2E validation tests
#
# ‚ö° ESTIMATED TIMES:
# - Phase 0 (Workspace Prep): 30-60 seconds
# - Phase 1A (Security): 3-4 minutes (parallel)
# - Phase 1B (Unit Tests): 3-4 minutes (parallel)
# - Phase 1C (Integration Tests): 4-5 minutes (parallel)
# - Phase 1D (E2E Tests): 8-12 minutes (conditional, after workspace prep)
# - Phase 2 (Build): 2-3 minutes (only on main, after all tests)
# - Phase 3 (Deploy): 3-5 minutes (only on main, production)
# - Total: 11-15 minutes (improved from 13-18 minutes due to parallel tests)
#
# üéØ IMPROVEMENTS:
# - 100% environment isolation (prevents race conditions)
# - PARALLEL unit and integration tests (saves 2-3 minutes)
# - Comprehensive test coverage with parallel security analysis
# - Enhanced security validation
# - Better error handling and reporting
# - Smart caching for dependencies
# - Conditional execution to save resources
# - Reliable testing environments with port separation
# - Independent test job outputs for better visibility
# =============================================================================
